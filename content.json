{"meta":{"title":"Aurora","subtitle":"","description":"成长","author":"Pock","url":"http://voidday.com"},"pages":[{"title":"tags","date":"2018-07-13T03:25:33.000Z","updated":"2018-07-13T06:09:12.148Z","comments":true,"path":"tags/index.html","permalink":"http://voidday.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2018-07-12T09:43:48.000Z","updated":"2018-07-13T06:08:54.225Z","comments":true,"path":"categories/index.html","permalink":"http://voidday.com/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"RabbitMQ笔记-4","slug":"RabbitMQ笔记-4","date":"2019-02-13T16:00:00.000Z","updated":"2019-03-19T08:04:06.869Z","comments":true,"path":"note/50cfc150.html","link":"","permalink":"http://voidday.com/note/50cfc150.html","excerpt":"这里记录官方的第3个Demo,这个Demo主要讲了交换器在MQ中的使用","text":"这里记录官方的第3个Demo,这个Demo主要讲了交换器在MQ中的使用 [TOC] To-do List 文章概要 交换器的类型 不使用交换器 fanout交换器 direct交换器 topic交换器 headers交换器 0X00 概要,以及记录完成情况 在前两个Demo中生产者和消费者是通过默认的交换器,也就是空字符串(channel.basicPublish()中的exchange参数为””),前面有解释过当exchange参数为空字符串的情况下,消息是通过routingKey指定的名称路由到队列（如果存在,是直接路由到队列）,并没有通过交换器,而MQ中消息传递模型核心思想是生产者永远不会降任何消息直接发送到队列.实际上，生产者通常甚至不知道消息是否会被传递到任何队列。 相反,生产者只能向交换器发送消息,而交换器处理起来也非常的简单.一方面它接收来自生产者的消息,另一方面它将接收到的这些消息推送到队列,交换器呢也需要知道它应该如何去处理它收到的消息它应该附加到特定队列吗？它应该附加到许多队列吗？或者它应该被丢弃,交换器的规则是由交换器的类型去定义 0X01 交换器的类型默认交换器,或者叫不使用交换器 生产者 12//消息通过routingKey指定的名称路由到队列（如果存在,是直接路由到队列）channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes(StandardCharsets.UTF_8)); 消费者 1channel.queueDeclare(QUEUE_NAME, false, false, false, null); 总结: 在默认交换器的情况下,生产者是直接将消息推送在队列,但是官方不推荐这样写 fanout类型的交换器 下图展示了fanout交换器的示意图 fanout交换器也叫扇形交换器,它会将收到的消息广播给所有的和它绑定的队列,在上图中P只关心消息发送到哪个交换器,由交换器X去觉得把消息放到哪个队列,二C3 C4只关心自己订阅了哪个队列 生产者代码编写 下面写一个完整的fanout交换器例子- 生产者 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package demo03;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;/** * 官方的第三个Demo 生产者 * 主要介绍了以下功能: * 1.Fanout交换器的使用 */public class FanoutSend &#123; /** * 定义交换器名称 */ private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) &#123; //配置连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); //try-with-resources try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); ) &#123; //声明交换器类型 channel.exchangeDeclare(EXCHANGE_NAME, \"fanout\"); //定义消息 String msg = \"你好\"; //通过通道把消息发送给交换器 channel.basicPublish(EXCHANGE_NAME, \"\", null, msg.getBytes(StandardCharsets.UTF_8)); System.out.println(\" [X] Sent '\" + msg + \"'\"); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者代码编写 下面写一个完整的fanout交换器例子- 消费者 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package demo03;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;/** * 对应官方Demo03的客户端 */public class FanoutRecv &#123; /** * 交换器名称 */ private static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //通道声明交换器 channel.exchangeDeclare(EXCHANGE_NAME, \"fanout\"); //通道声明一个不为持久的队,独占的(仅限此连接),自动删除的(服务器不在使用或者下线将此队列删除)队列 String queueName = channel.queueDeclare().getQueue(); //将队列绑定到交换器 channel.queueBind(queueName, EXCHANGE_NAME, \"\"); System.out.println(\" [*] 正在等待消息,退出请按 CTRL+C\"); //消息确认,关闭自动确认// DeliverCallback xx = new DeliverCallback() &#123;// @Override// public void handle(String s, Delivery delivery) throws IOException &#123;// String msg = new String(delivery.getBody(), StandardCharsets.UTF_8);// System.out.println(\" [X] 收到消息'\" + msg + \"',我的工作编号为 FanoutRecv\");// channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);// &#125;// &#125;;// channel.basicConsume(queueName, false, xx, consumerTag -&gt; &#123;&#125;); DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String msg = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\" [X] 收到消息'\" + msg + \",我的工作编号为 FanoutRecv'\"); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; channel.basicConsume(queueName, false, deliverCallback, consumerTag -&gt; &#123;&#125;); &#125;&#125; 代码中的一些API介绍(基于5.6.0 AP)生产者的代码 channel.exchangeDeclare() 此方法被重载了8次….精力有限,有能力可以参考RabbitMQ-exchangeDeclare方法API) channel.exchangeDeclare(java.lang.String exchange, java.lang.String type) 主动声明一个非自动删除，非持久的交换，没有额外的参数 参数名 参数类型 参数意义 exchange String 交换器的名称(比如上面生产者代码中的”logs”) type String 定义交换器的类型(代码中的”fanout”类型交换器) channel.basicPublish() 此方法被重载了3次,参考RabbitMQ-basicPublish方法API) channel.basicPublishjava.lang.String exchange, java.lang.String routingKey, AMQP.BasicProperties props, byte[] body) 参数名 参数类型 参数意义 exchange String 消息需要发送到的交换器名称(比如上面生产者代码中的”logs”) routingKek String 路由器密钥 props AMQP.BasicProperties 消息的其他属性 - 路由头等 body byte[] 消息正文 消费者的代码 channel.basicAck() 详细文档参考RabbitMQ-basicAck方法API) basicAck(long deliveryTag, boolean multiple) 参数名 参数类型 参数意义 deliveryTag long RabbitMQ推送消息给消费者时，会附带一个DeliveryTag，以便消费者可以在消息确认时告诉 RabbitMQ 到底是哪条消息被确认了。RabbitMQ 保证在每个信道中，每条消息的 Delivery Tag 从 1 开始递增 multiple boolean 取值为 false 时，表示通知 RabbitMQ 当前消息被确认；如果为 true，则额外将比第一个参数指定的 delivery tag 小的消息一并确认。（批量确认针对的是整个信道，参考gordon.study.rabbitmq.ack.TestBatchAckInOneChannel.java。） 对同一消息的重复确认，或者对不存在的消息的确认，会产生 IO 异常，导致信道关闭。 channel.basicConsume() 此方法重载太多次没去数了…,详细文档参考RabbitMQ-basicConsume方法API) basicConsume(java.lang.String queue, boolean autoAck, DeliverCallback deliverCallback, CancelCallback cancelCallback) 参数名 参数类型 参数意义 queue String 队列名称 autoAck boolean 是否自动确认消息(手动确认和自动确认,在开发中一般为手动确认,即值为false,详细说明参考Consumer Acknowledgements and Publisher Confirms) deliverCallback deliverCallback 传递消息时的回调 cancelCallback CancelCallback 取消消费者时的回调(这个是个功能性接口可以用作lambda表达式或方法引用的赋值目标) direct类型的交换器 下图展示了direct交换器的原理图 上图可以看到 direct类型的交换器x和两个通道绑定,分别是Q1和Q2,第一个队列Q1绑定orange的路由key(routingKey),而Q2则绑定的black和green的路由key 在这种配置下P(生产者)发送消息到X(direct交换器),交换器根据消息的routingKey(路由key)的不同将消息分配到不同的队列(Q1,Q2) 图中orangekey的消息被分配到了Q1,因为Q1队列绑定的orange;而black,green被交换器分配到了Q2,因为Q2队列绑定了black和green的路由key 使用相同的路由key去绑定多个队列是完全没有问题的,如下图所示 上图中Q1,Q2都绑定了路由keyblack,在这种情况下,direct交换器类型就表现的和fanout类型一样了 生产者代码编写 下面为Driect类型的交换器的生产者代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package demo04;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;/** * 官方的第4个Demo * 主要实现了以下内容: * 1.direct类型交换器的使用 */public class DirectSend &#123; /** * 定义交换器的名称 */ public static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) &#123; //配置连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); //try-with-resources try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel() ) &#123; //声明交换器类型 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); //定义Info消息(消费者只有在routingKek相同时才能接收到消息) String infoMsg = \"你好 direct\"; //定义Error消息 String errorMsg = \"错误 direct\"; //消息发送 channel.basicPublish(EXCHANGE_NAME, \"info\", null, infoMsg.getBytes(StandardCharsets.UTF_8)); System.out.println(\" [X] Sent '\" + infoMsg + \"'\"); //错误消息发送 channel.basicPublish(EXCHANGE_NAME, \"error\", null, errorMsg.getBytes(StandardCharsets.UTF_8)); System.out.println(\" [X] Sent '\" + errorMsg + \"'\"); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者代码编写负责接收Info路由key12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package demo04;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;/** * 对应官方Demo04的客户端 * 负责接收Info */public class DirectRecvForInfo &#123; /** * 交换器名称 */ public static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //配置连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //声明交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); //通过通道声明一个不为持久的队,独占的(仅限此连接),自动删除的(服务器不在使用或者下线将此队列删除)队列 String queueName = channel.queueDeclare().getQueue(); //绑定到交换器 channel.queueBind(queueName, EXCHANGE_NAME, \"info\"); System.out.println(\" [*] 正在等待消息,退出请按 CTRL+C\"); DeliverCallback deliverCallback = (consumerTar, delivery) -&gt; &#123; String msg = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\" [X] 收到消息'\" + msg + \",我的工作编号为 DirectRecv,负责接收 Info 消息'\"); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; channel.basicConsume(queueName, false, deliverCallback, consumerTag -&gt; &#123;&#125;); &#125;&#125; 负责接收Error路由key12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package demo04;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;/** * 对应官方Demo04的客户端 * 负责接error */public class DirectRecvForError &#123; /** * 交换器名称 */ public static final String EXCHANGE_NAME = \"logs\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //配置连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //声明交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); //通过通道声明一个不为持久的队,独占的(仅限此连接),自动删除的(服务器不在使用或者下线将此队列删除)队列 String queueName = channel.queueDeclare().getQueue(); //绑定到交换器 channel.queueBind(queueName, EXCHANGE_NAME, \"error\"); System.out.println(\" [*] 正在等待消息,退出请按 CTRL+C\"); DeliverCallback deliverCallback = (consumerTar, delivery) -&gt; &#123; String msg = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\" [X] 收到消息'\" + msg + \",我的工作编号为 DirectRecv,负责接收 Error 消息'\"); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; channel.basicConsume(queueName, false, deliverCallback, consumerTag -&gt; &#123;&#125;); &#125;&#125; 代码效果展示 生产者发送消息 消费者负责Info类型接收消息 消费者负责Error类型接收消息 这里说一下上面介绍Direct交换器没有说到的地方就拿这个代码举例,当直接启动生产者发送消息,不启动两个消费者消息会丢失,只启动一个消费者,发送给另一个消费者的消息会丢失 代码中的一些API介绍(基于5.6.0 AP) 这里就暂时只说一下上面没说的,有空我会把API整合到一个地方 消费者的代码 channel.queueBind() 此方法被重载了2次….精力有限,有能力可以参考RabbitMQ-queueBind方法API) channel.queueBind(java.lang.String queue, java.lang.String exchange, java.lang.String routingKey) 主动声明一个非自动删除，非持久的交换，没有额外的参数 参数名 参数类型 参数意义 queue String 通道名称 exchange String 交换器名称 routingKey String 路由Key topic类型的交换器 下图展示了topic交换器的原理 消息分发规则: 一个附带特殊的选择键将会被转发到绑定键与之匹配的队列中。 路由key规则:路由key必须是由点隔开的一系列的标识符组成：”stock.usd.nyse”,“nyse.vmw”,”quick.orange.rabbit”.你可以定义任数量的标识符，上限为255个字节。 通道绑定的key: 这个有点类似于正则表达式的意思了,如下表: 表达式 匹配意义 * (星号)可以替代一个单词(或者标识符) # (hash)可以替换零个或多个单词(或者标识符) 图示意义解释: 消息1(fast.orange.)通过交换器(topic类型)分配到消费者Q6(#)和Q7(.orange.*),因为Q6的#(hash)可以匹配任意标识符,而Q7的orange.(星号)匹配前后的一个单词或者标识符,所以这两个通道都能收到消息,消息2(lazy.orange.a.b)通过交换器会到达Q6.Q8,因为Q6匹配所有,而Q8(lazy.#)可以匹配lazy.后面的零个或者多个标识符 生产者代码编写12345678910111213141516171819202122232425262728293031323334353637383940414243444546package demo05;import com.rabbitmq.client.BuiltinExchangeType;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class TopicSend &#123; //定义交换器名称 private static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] args) &#123; //配置连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); //tyr-witch-resources try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel();) &#123; //声明交换器类型 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); //定义消息 String msg = \"# 匹配\"; //消息发送 channel.basicPublish(EXCHANGE_NAME, \"anonymous.info\", null, msg.getBytes(StandardCharsets.UTF_8)); System.out.println(\" [X] Sent '\" + msg + \"'\"); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者代码编写12345678910111213141516171819202122232425262728293031323334353637383940414243444546package demo05;import com.rabbitmq.client.*;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class TopicRecvForJinHao &#123; /** * 交换器名称 */ public static final String EXCHANGE_NAME = \"topic_logs\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //配置连接信息 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"admin\"); factory.setPassword(\"123456\"); Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //声明交换器 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); //通过通道声明一个不为持久的队,独占的(仅限此连接),自动删除的(服务器不在使用或者下线将此队列删除)队列 String queueName = channel.queueDeclare().getQueue(); //绑定到交换器,配置匹配key为 # 接收所有类型消息 channel.queueBind(queueName, EXCHANGE_NAME, \"#\"); System.out.println(\" [*] 正在等待消息,退出请按 CTRL+C\"); DeliverCallback deliverCallback = (consumerTar, delivery) -&gt; &#123; String msg = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\" [X] 收到消息'\" + msg + \",我的路由Key为 # ,负责接收所有消息'\"); channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125;; channel.basicConsume(queueName, false, deliverCallback, consumerTag -&gt; &#123;&#125;); &#125;&#125; 代码效果展示 生产者发送消息如图所示 消费者#号接收消息 其它说明 上面的代码只是一个最简单的demo状态而且只是实验了 # 匹配而已,你们可以启动两个生产者并且使用不同的路由key,然后在启动两个消费者使用不同的匹配规则,就可以实现类似于示例图的效果了","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ笔记-3","slug":"RabbitMQ笔记-3","date":"2019-01-23T16:00:00.000Z","updated":"2019-02-13T04:39:20.362Z","comments":true,"path":"note/ceab54f3.html","link":"","permalink":"http://voidday.com/note/ceab54f3.html","excerpt":"这里记录官方的第2个demo,这个demo中主要讲的MQ的队列和消费者在处理消息的同时挂掉了的情况消息怎么去处理,以及任务的公平调度","text":"这里记录官方的第2个demo,这个demo中主要讲的MQ的队列和消费者在处理消息的同时挂掉了的情况消息怎么去处理,以及任务的公平调度 [TOC] 0-概要 在官方的第一个Demo中只有一个消费者,而且任务简单并没有在真实情况下进行模拟,比如遇到处理复杂的任务需要处理几秒钟的那种,在这个Demo中将使用Thread.sleep()进行模拟复杂任务的等待情况,并且启动第二个消费者 1-循环调度简单实现 任务队列是要是避免立即执行复杂型任务,并且立即执行,我们需要把它封装成一个任务放到任务队列.后台将执行任务.当运行多个工作进程(消费者)时它们之间可以共享任务 循环调度的有点就是任务可以并行执行,假如任务数量巨大,我们可以添加更多的消费者,扩展起来非常轻松 如下图 1.1-生产者Java端编写12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package demo02;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;/** * 官方Demo 02 生产者 */public class NewTask &#123; /** * 定义队列名称 */ private final static String QUEUE_NAME = \"task_queue\"; public static void main(String[] args) &#123; //创建一个连接 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"user\"); factory.setPassword(\"123456\"); //注意这里使用了 try-with-resources, try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; //普通队列声明 //参数的大概意思 参数1 queue : 队列名称 // 参数2 Durable : 是否持久化队列(该队列在服务器重启过后存活) // 参数3 exclusive : 是否声明一个排他性队列(以后在写文章进行统一解释MQ的队列类型) // 参数4 autoDelete : 是否声明一个自动删除的队列 // 参数5 arguments : 队列的其它属性(构造参数) channel.queueDeclare(QUEUE_NAME, false, false, false, null); /** * 持久化队列声明,参数 durable 为 true * channel.queueDeclare(QUEUE_NAME, true, false, false, null); */ String message = \"Hello My Name Is Task 01 \"; //普通消息声明 // 参数1 exchange : 交换机名称,默认的话是空字符串,消息通过routingKey指定的名称路由到队列（如果存在,是直接路由到队列） // 参数2 routingKey : 路由的key 我理解为指定消息发送到哪个队列 // 参数3 BasicProperties : 可以自行查看BasicProperties类的定义 channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes(StandardCharsets.UTF_8)); /** * 持久化消息声明,修改了BasicProperties参数 * channel.basicPublish(\"\", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes(StandardCharsets.UTF_8)) */ System.out.println(\" [x] Sent '\" + message + \"'\"); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 1.2-消费者Java端编写123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package demo02;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.Arrays;import java.util.concurrent.TimeoutException;/** * 官方Demo 02 消费者 */public class Work &#123; /** * 队列名称,保持与send端一样 */ private final static String QUEUE_NAME = \"task_queue\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //连接 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"user\"); factory.setPassword(\"123456\"); //为什么这里不使用 try-with-resource语句来自动关闭通道和连接？ //因为在生产者中给 队列发送消息过后关闭连接没有什么影响 //但是在 消费者中,需要异步监听,当消息到达时需要保持进程在活跃中 Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //队列声明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(\" [*] Waiting for messages. To exit press CTRL+C\"); //它将缓冲消息,直到准备使用它,这就是DeliverCallback子类的作用 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\" [x] Received '\" + message + \"'\"); try &#123; doWork(message); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\" [X] Done My Num is 01\"); &#125; &#125;; boolean autoAck = true; channel.basicConsume(QUEUE_NAME, autoAck, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125; /** * 模拟处理耗时任务 * * @param task * @throws InterruptedException */ private static void doWork(String task) throws InterruptedException &#123; Thread.sleep(10000); &#125;&#125; 1.3-效果展示 我们复制一份Work.java的代码,把它当做第二个消费者去共同处理任务,生产者发送消息过后,第一个被调度的消费者处理消息需要等待10秒,再次发送消息不会发送到第一个消费者去,而是发送到第二个消费者去处理 效果如下图 可以看出任务是被轮训调度给消费者的 2-消息确认 当任务调度到消费者过后,开始处理任务的过程当中消费者因为各种原因下线了会发生什么.如果使用上面的Demo进行测试的话,一旦MQ向消费者发送了消息,消息将立刻标记为删除,在这种情况下如果一个消费者在处理任务的过程中下线了,会丢失刚刚处理的任务,还将丢失发送给这个消费者但是还没开始处理的所有消息 我们希望的是当消费者意外下线的情况发送,任务将会交给另外一个消费者进行处理 为了保证消息永不丢失,MQ支持 message acknowledgments(消息确认),消费者发回ack(nowledgement) 告诉MQ已收到,处理了消息MQ可以自由删除它 如果消费者意外下线,channel(通道)关闭, connection(连接)关闭,或者TCP连接丢失 而没有发送确认,MQ将理解为消息未完成处理并且将重新放入队列中.如果同时还有其它消费者在线,则会迅速将其发送给其它消费者.这样就可以确保即使消费者下线,消息也不会丢失 在默认情况下,Manual message acknowledgments(手动消息确认) 是已经打开的,但是在上面的代码中我们已经关闭了它,使用的autoAck=true ,在真实情况下一旦我们完成的任务,就应该将此标志设置为false并从消费者发送确认 2.1-消息确认Java消费者端代码 修改过的消费者代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package demo02;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;import java.io.IOException;import java.nio.charset.StandardCharsets;import java.util.concurrent.TimeoutException;public class Work02 &#123; /** * 队列名称,保持与send端一样 */ private final static String QUEUE_NAME = \"task_queue\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //连接 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"182.61.24.136\"); factory.setUsername(\"demoUser\"); factory.setPassword(\"Yilunjk123\"); //为什么这里不使用 try-with-resource语句来自动关闭通道和连接？ //因为在生产者中给 队列发送消息过后关闭连接没有什么影响 //但是在 消费者中,需要异步监听,当消息到达时需要保持进程在活跃中 Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //队列声明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(\" [*] Waiting for messages. To exit press CTRL+C\"); //它将缓冲消息,直到准备使用它,这就是DeliverCallback子类的作用 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(\" [x] Received '\" + message + \"'\"); try &#123; doWork(message); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\" [X] Done My Num is 02\"); //添加的消息确认 channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false); &#125; &#125;; //关闭了自动确认 boolean autoAck = false; channel.basicConsume(QUEUE_NAME, autoAck, deliverCallback, consumerTag -&gt; &#123; &#125;); &#125; /** * 模拟处理耗时任务 * * @param task * @throws InterruptedException */ private static void doWork(String task) throws InterruptedException &#123; Thread.sleep(10000); &#125;&#125; 2.2-效果演示 生产者发送消息 消费者1接收到消息,但是处理过程中下线 任务被重新调度到消费者2进行处理 3-消息持久化(或者叫队列和消息的持久化) 上面的例子中确保了即使消费者下线,任务也不会丢失.但是MQ服务停止,我们的任务任然会丢失 队列持久化可以通过在声明队列的时候进行持久化队列,如下图(修改生产者代码中的队列声明部分,消费者一样需要修改) 12//持久化队列声明,参数 durable 为 truechannel.queueDeclare(QUEUE_NAME, true, false, false, null); 消息持久化只需要修改生产者的消息发送部分,如下图 12//持久化消息声明,修改了BasicProperties参数channel.basicPublish(\"\", QUEUE_NAME, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes(StandardCharsets.UTF_8)) 4-公平派遣 MQ的默认消息调度是轮训的,就像上面的例子,第一个任务给A如果有第二个消息,任务就给B,第三个消息任务就又给A.这样的调度会造成消费者的任务堆积假如在处理复杂任务的情况下,这种情况下可以在消费者中的队列中设置每次只接受一个消息,只有处理完过后才接受第二个消息 在消费者中设置如下 12int prefetchCount = 1 ;channel.basicQos（prefetchCount）; 消费者如下图: 这样的话在任务过多加上任务复杂的情况下可能会造成队列里面任务堆积太多,所以要及时的添加消费者","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ笔记-2","slug":"RabbitMQ笔记-2","date":"2019-01-20T16:00:00.000Z","updated":"2019-02-13T02:38:43.359Z","comments":true,"path":"note/b9ac6465.html","link":"","permalink":"http://voidday.com/note/b9ac6465.html","excerpt":"这篇笔记主要记录MQ官方的第一个Demo,这里我用的是mvn构建","text":"这篇笔记主要记录MQ官方的第一个Demo,这里我用的是mvn构建 [TOC] demo-01-“Hello World!” 在本教程的这一部分中，我们将用Java编写两个程序; 发送单个消息的生产者，以及接收消息并将其打印出来的消费者。我们将掩盖Java API中的一些细节，专注于这个非常简单的事情，只是为了开始。这是消息传递的“Hello World”。 官方的图片示例如下: 在上图中,”P”为生产者,”C”为消费者.中间为队列 - RabbitMQ代表消费者保留的消息缓冲区。 1.pom引入jar 引入pom 123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.5.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt; &lt;version&gt;1.7.22&lt;/version&gt;&lt;/dependency&gt; 2.消息发送流程 图片示例如下 上图中”P”为生产者正在向队列中存入消息,这里的java就要写出这个流程 2.1-java生产者代码编写123456789101112131415161718192021222324252627282930313233343536import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import java.io.IOException;import java.util.concurrent.TimeoutException;public class Send &#123; /** ** 声明队列的名字 **/ private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) &#123; //创建一个连接 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"demoUser\"); factory.setPassword(\"123456\"); //声明队列(声明队列是幂等性的,只有在它不存在的情况下才会创建它),注意这里使用了 try-with-resources, try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) &#123; channel.queueDeclare(QUEUE_NAME, false, false, false, null); String message = \"Hello World!\"; channel.basicPublish(\"\", QUEUE_NAME, null, message.getBytes(\"UTF-8\")); System.out.println(\" [x] Sent '\" + message + \"'\"); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 3.消息接收流程 消费者监听RabbitMQ的消息,因此与发布单个消息的发布者不同，我们将保持其运行以侦听消息并将其打印出来。 示例图如下 3.1-java消费者代码编写1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.DeliverCallback;import java.io.IOException;import java.util.concurrent.TimeoutException;public class Recv &#123; /** * 队列名称,保持与send端一样 */ private final static String QUEUE_NAME = \"hello\"; public static void main(String[] args) throws IOException, TimeoutException &#123; //连接 ConnectionFactory factory = new ConnectionFactory(); factory.setHost(\"127.0.0.1\"); factory.setUsername(\"demoUser\"); factory.setPassword(\"123456\"); //为什么这里不使用 try-with-resource语句来自动关闭通道和连接？ //因为在生产者中给 队列发送消息过后关闭连接没有什么影响 //但是在 消费者中,需要异步监听,当消息到达时需要保持进程在活跃中 Connection connection = factory.newConnection(); Channel channel = connection.createChannel(); //队列声明 channel.queueDeclare(QUEUE_NAME, false, false, false, null); System.out.println(\" [*] Waiting for messages. To exit press CTRL+C\"); //它将缓冲消息,直到准备使用它,这就是DeliverCallback子类的作用 DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; String message = new String(delivery.getBody(), \"UTF-8\"); System.out.println(\" [x] Received '\" + message + \"'\"); &#125;; channel.basicConsume(QUEUE_NAME, true, deliverCallback, consumerTag -&gt; &#123;&#125;); &#125;&#125; 4.运行效果 生产者 消费者","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ笔记-1","slug":"RabbitMQ笔记-1","date":"2019-01-18T01:45:19.000Z","updated":"2019-02-12T09:49:03.235Z","comments":true,"path":"note/20a535df.html","link":"","permalink":"http://voidday.com/note/20a535df.html","excerpt":"最近遇到了任务的问题,想采用一种高效成熟的消息队列去处理,所以就开始看看RabbitMQ","text":"最近遇到了任务的问题,想采用一种高效成熟的消息队列去处理,所以就开始看看RabbitMQ [TOC] RabbitMQ的历史 RbitMQ是一个Erlang开发的AMQP（Advanced Message Queuing Protocol ）的开源实现。AMQP 的出现其实也是应了广大人民群众的需求，虽然在同步消息通讯的世界里有很多公开标准（如 Cobar）的 IIOP ，或者是 SOAP 等），但是在异步消息处理中却不是这样，只有大企业有一些商业实现（如微软的 MSMQ ，IBM 的 WebSphere MQ 等），因此，在 2006 年的 6 月，Cisco 、Red Hat、iMatix 等联合制定了 AMQP 的公开标准。 RabbitMQ由RabbitMQ Technologies Ltd开发并且提供商业支持的。该公司在2010年4月被SpringSource（VMware的一个部门）收购。在2013年5月被并入Pivotal。其实VMware，Pivotal和EMC本质上是一家的。不同的是，VMware是独立上市子公司，而Pivotal是整合了EMC的某些资源，现在并没有上市。 RabbitMQ简述 RabbitMQ是一个实现AMQP的消息中间件,其服务器端使用Erlang语言编写 需要发送邮件的人,先把邮件放到邮箱(这里邮箱就相当于MQ中的队列),后面邮箱中的邮件(相当于在队列中的信息)被送到指定人的手中,然后收件人需要确认收到 需要发送邮件的人,先把邮件放到邮箱(这里邮箱就相当于MQ中的队列),后面邮箱中的邮件(相当于在队列中的信息)被送到指定人的手中,然后收件人需要确认收到","categories":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/categories/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://voidday.com/tags/RabbitMQ/"}]},{"title":"Mysql索引基数","slug":"Mysql索引基数","date":"2018-09-28T02:50:42.000Z","updated":"2018-09-29T02:45:26.420Z","comments":true,"path":"note/4fd09d4d.html","link":"","permalink":"http://voidday.com/note/4fd09d4d.html","excerpt":"做学习记录","text":"做学习记录 0X00 在Mysql中的索引分类主键索引 主键索引(Primary Key) 一张表中只能有一个主键索引 一般情况下不需要人工去设置主键索引,因为默认主键有索引 主键索引也是唯一的,不允许重复的索引 常规索引 常规索引(普通索引,index或key) 一张表中可以有多个常规索引 常规索引可以用于重复字段,例如年级表中的班级字段 唯一索引 唯一索引(Unique Key) 一张表中也可以有多个唯一索引,但是唯一索引的字段不能包含重复值,例如年级表中的班级字段在表中肯定会重复出现,索引班级字段不能当做唯一索引 全文索引 全文索引(Full Text) 表示 全文搜索的索引,FULLTEXT用于搜索很长一篇文章的时候,效果最好 用在比较短的文本，如果就一两行字的,普通的 INDEX 也可以 复合索引(联合索引,组合索引) 复合索引,这个知识比较多 两个或更多个列上的索引被称作复合索引,如（index_A,index_B,index_C） 复合索引在数据库操作期间所需的开销更小,可以代替多个单一索引; 同时有两个概念叫做窄索引和宽索引,窄索引是指索引列为1-2列的索引,宽索引也就是索引列超过2的索引; 设计索引的一个重要原则就是能用窄索引不用宽索引,因为窄索引往往比组合索引更有效; 组合索引遵循最左原则,当建立索引（index_A,index_B,index_C）时,有效索引为(index_A),(index_A,index_B),(index_A,index_C),(index_A,index_B,index_C),无效索引为(index_B),(index_C),(index_B,index_C),下面有实际例子 单独使用字段index_A,可以看到type为ref使用了索引单独使用字段index_B,可以看到type为index,之比ALL好一点,但是还是扫描的全表,效率不行单独使用字段index_C,可以看到type为index,之比ALL好一点,但是还是扫描的全表,效率不行使用组合字段,(index_A,index_B),可以看到type为ref使用了索引使用组合字段,(index_A,index_C),可以看到type为ref使用了索引使用组合字段,(index_A,index_B,index_C),可以看到type为ref使用了索引使用组合字段,(index_B,index_C),可以看到type为index,之比ALL好一点,但是还是扫描的全表,效率不行 更多资料sql查询用到索引的条件是必须要遵守最左前缀原则，为什么上面有些查询还能用到index类型的索引？ 上面查询type字段分别有: index,ref 解释: index：这种类型表示是mysql会对整个该索引进行扫描。要想用到这种类型的索引，对这个索引并无特别要求，只要是索引，或者某个复合索引的一部分，mysql都可能会采用index类型的方式扫描。但是呢，缺点是效率不高，mysql会从索引中的第一个数据一个个的查找到最后一个数据，直到找到符合判断条件的某个索引。 所以当使用字段index_B时,sql语句为SELECT * FROM test_index WHERE index_B = &#39;b&#39;,索引为(index_A,index_B,index_C),index_B为复合索引的一部分,没有问题,可以进行index类型的索引扫描方式。explain显示结果使用到了索引，是index类型的方式。 解释: ref:这种类型表示mysql会根据特定的算法快速查找到某个符合条件的索引，而不是会对索引中每一个数据都进行一一的扫描判断，也就是所谓你平常理解的使用索引查询会更快的取出数据。而要想实现这种查找，索引却是有要求的，要实现这种能快速查找的算法，索引就要满足特定的数据结构。简单说，也就是索引字段的数据必须是有序的，才能实现这种类型的查找，才能利用到索引。 疑问: 索引不都是进行了有序排序吗? 解释: 在单个索引下,索引的字段肯定是有序排序的,但是在复合索引下情况就不一样了,复合索引中排序方式也是按照最左原则,比如上面例子的复合索引,排序就是排序最左的index_A,所以第一个index_A字段是绝对有序的，而第二字段就是无序的了。所以通常情况下，直接使用第二个index_B字段进行条件判断是用不到索引的，当然，可能会出现上面的使用index类型的索引。这就是所谓的mysql为什么要强调最左前缀原则的原因。 复合索引可以和唯一索引结合在一起使用,也可以和常规索引结合一起使用,比如和唯一索引结合一起使用时,必须保证两个索引的字段在表中都不包含重复值,常规索引则满足常规索引要求即可 这个其实不应该算到索引分类里面的,因为这个相当于结合体 最后引用博主SunnyAmy的图片 外键索引 外键索引(外键索引) 外键索引我暂时没有接触过这里引用下脚本之家中的介绍吧 外键索引（Foreign Key），简称外键，它可以提高查询效率，外键会自动和对应的其他表的主键关联。外键的主要作用是保证记录的一致性和完整性 注意：只有InnoDB存储引擎的表才支持外键。外键字段如果没有指定索引名称，会自动生成。如果要删除父表（如分类表）中的记录，必须先删除子表（带外键的表，如文章表）中的相应记录，否则会出错。 创建表的时候，可以给字段设置外键，如 foreign key(cate_id) references cms_cate(id)，由于外键的效率并不是很好，因此并不推荐使用外键，但我们要使用外键的思想来保证数据的一致性和完整性。 复合索引的排序选择 由于复合索引东西有点多,这里在补充一下 怎样去选择合适的索引列顺序 引用脚本之家文章的介绍 最容易引起困惑的就是复合索引中列的顺序。在复合索引中，正确地列顺序依赖于使用该索引的查询，并且同时需要考虑如何更好地满足排序和分组的需要。索引列的顺序意味着索引首先按照最左列进行排序，其次是第二列，第三列…。所以，索引可以按照升序或者降序进行扫描，以满足精确符合列顺序的order by、group by和distinct等子句的查询需求。当不需要考虑排序和分组时，将选择性最高的列放到复合索引的最左侧（最前列）通常是很好的。这时，索引的作用只是用于优化where条件的查找。但是，可能我们也需要根据那些运行频率最高的查询来调整索引列的顺序，让这种情况下索引的选择性最高。 怎么去选择排序的例子,有条sql为select * from payment where order_id = 65421 and older_id = 88941;,这种情况下如何去排列复合索引中的older_id和older_id呢? 使用show index from 表名使用索引基数(cardinality)/数据总量得到的值,越接近1该索引的选择性越高 使用select count(distinct 列名)/count(*) ,count(distinct 列名2)/count(*) from 表名能看出来order_id的值最大,选择性最高,所以复合索引的排列最好为(order_id,older_id) 尽管，关于选择性和全局基数的经验法则值得去研究和分析，但一定别忘了order by、group by 等因素的影响，这些因素可能对查询的性能造成非常大的影响。 0X01 索引的方式方法B-Tree 索引 B-Tree 索引 B-Tree 索引(B树(可以是多叉树)),也是主流的索引方法 B-Tree 对索引列是顺序存储的,因此很适合查找范围数据。它能够加快访问数据的速度,因为存储引擎不再需要进行全表扫描来获取需要的数据 HASH 哈希索引(key,value) 哈希索引 哈希索引这种方式对范围查询支持得不是很好 哈希索引只有精确匹配索引所有列的查询才有效。在MySQL中，只有Memory引擎显示支持哈希索引。 Mysql索引基数的概念 这里就用工具Navicat做记录吧,方便点,命令行太难看了…. 索引基数(cardinality): 索引中不重复的索引值的数量 比如,有一张消费记录表,其中的字段消费者ID设置了索引,全表有5条数据,其中消费者ID为2的人记录了两次,数据大致为(1,2,2,3,4),这时索引的基数就为4 索引基数相对于数据表行数较高（也就是说，列中包含很多不同的值，重复的值很少）的时候，它的工作效果最好。 如果某个数据列用于记录性别（只有”Man”和”Wman”两种值），那么索引的用处就不大。因为选择其中的任意一个索引都可以得到大约一半的数据行,查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。惯用的百分比界线是”30%”。 索引基数的查看 show index from 表名 Cardinality列中的数即为索引基数,但是是估计值不是准确值 为何是估计值而不是准确值? 在生产环境中，数据表的更新操作非常频繁，每一次的数据更新操作，都会更新索引文件中的数据，而如果每次都要进行一次该索引中不同索引值的统计会增加系统压力 索引基数的初始值 新表中添加索引：索引基数为0 旧表中添加索引：索引基数为当前表中数据总数 索引基数的计算方式 采用采样的方法，默认情况下InnoDB会对8个叶子节点的信息进行统计，过程如下: 取得B+Tree所有叶子节点的数量，记为A 随机取得B+Tree索引的8个叶子节点。统计每个叶子节点的不同记录的条数，即为P1,P2,…,P8 根据采样计算出Cardinality的预估值：Cardinality=（P1+P2+…+P8）*A/8 索引基数的更新语句ANALYZE 表名 何时自动更新索引基数的值？ 表中的1/16数据已发生变化：上一次统计Cardinality信息后，表中1/16数据已发生变化，则会触发Cardinality统计 start_modified_counter&gt;2 000 000 000：为对表中某一行数据频繁进行更新操作，实际数据条数并没有发生变化，则InnoDB会生成start_modified_counter计数器，用来统计操作次数，如果次数大于2 000 000 000，则会触发Cardinality统计 show index、ANALYZE TABLE、SHOW TABLE STATUS以及访问INFOMATION_SCHEMA架构下的TABLES或STATISTICS会导致Cardinality的统计 下面看一下show index from 表名 结果中各列的含义引用博主命运的左岸","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://voidday.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://voidday.com/tags/Mysql/"}]},{"title":"SpringBoot 整合druid","slug":"SpringBoot 整合druid","date":"2018-09-05T09:14:14.000Z","updated":"2018-09-05T09:26:57.775Z","comments":true,"path":"note/eae56122.html","link":"","permalink":"http://voidday.com/note/eae56122.html","excerpt":"最近在完善框架,这里整合一下druid,监控下慢查询,方便后期优化","text":"最近在完善框架,这里整合一下druid,监控下慢查询,方便后期优化 pom.xml相关依赖123456&lt;!--阿里 Druid Spring Boot Starter依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt; &lt;/dependency&gt; application.properties配置 这里没有使用yml的方式配置 123456789101112131415161718192021222324#连接池配置# 初始化大小，最小，最大spring.datasource.druid.initial-size=5spring.datasource.druid.min-idle=1spring.datasource.druid.max-active=50# 配置获取连接等待超时的时间，单位是毫秒spring.datasource.druid.max-wait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.datasource.druid.time-between-eviction-runs-millis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.datasource.druid.min-evictable-idle-time-millis=300000spring.datasource.druid.validation-query= SELECT 1 FROM DUALspring.datasource.druid.test-while-idle=truespring.datasource.druid.test-on-borrow=falsespring.datasource.druid.test-on-return=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.datasource.druid.pool-prepared-statements=false#spring.datasource.maxPoolPreparedStatementPerConnectionSize=20# 配置监控统计拦截的filters，去掉后监控界面sql无法统计，&apos;wall&apos;用于防火墙#spring.datasource.filters=stat,wall,log4j# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.datasource.druid.connection-properties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000# 合并多个DruidDataSource的监控数据#spring.datasource.useGlobalDataSourceStat=true ##配置config,ben的形式配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.company.project.configurer;import com.alibaba.druid.pool.DruidDataSource;import com.alibaba.druid.support.http.StatViewServlet;import com.alibaba.druid.support.http.WebStatFilter;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.boot.web.servlet.ServletRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.PropertySource;import javax.sql.DataSource;/** * @author 七渣渣 * @date 2018年9月5日16:12:40 */@Configuration@PropertySource(value = \"classpath:application.properties\")public class DruidConfigurer &#123; @Bean(destroyMethod = \"close\", initMethod = \"init\") @ConfigurationProperties(prefix = \"spring.datasource\") public DataSource druidDataSource() &#123; DruidDataSource druidDataSource = new DruidDataSource(); return druidDataSource; &#125; /** * 注册一个StatViewServlet * @return */ @Bean public ServletRegistrationBean druidStatViewServlet()&#123; //org.springframework.boot.context.embedded.ServletRegistrationBean提供类的进行注册. ServletRegistrationBean servletRegistrationBean = new ServletRegistrationBean(new StatViewServlet(),\"/druid/*\"); //添加初始化参数：initParams //白名单： servletRegistrationBean.addInitParameter(\"allow\",\"127.0.0.1\"); //IP黑名单 (存在共同时，deny优先于allow) : 如果满足deny的话提示:Sorry, you are not permitted to view this page. servletRegistrationBean.addInitParameter(\"deny\",\"192.168.1.73\"); //登录查看信息的账号密码. servletRegistrationBean.addInitParameter(\"loginUsername\",\"admin\"); servletRegistrationBean.addInitParameter(\"loginPassword\",\"123456\"); //是否能够重置数据. servletRegistrationBean.addInitParameter(\"resetEnable\",\"false\"); return servletRegistrationBean; &#125; /** * 注册一个：filterRegistrationBean * @return */ @Bean public FilterRegistrationBean druidStatFilter()&#123; FilterRegistrationBean filterRegistrationBean = new FilterRegistrationBean(new WebStatFilter()); //添加过滤规则. filterRegistrationBean.addUrlPatterns(\"/*\"); //添加不需要忽略的格式信息. filterRegistrationBean.addInitParameter(\"exclusions\",\"*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*\"); return filterRegistrationBean; &#125;&#125; 访问http://127.0.0.1:8080/druid/","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"}]},{"title":"Mysql 8.0 配置主从备份","slug":"Mysql 8.0 配置主从备份","date":"2018-08-30T02:32:42.000Z","updated":"2018-09-05T09:26:57.767Z","comments":true,"path":"note/873aa52d.html","link":"","permalink":"http://voidday.com/note/873aa52d.html","excerpt":"新的架构需要读写分离,这里配置下主从备份","text":"新的架构需要读写分离,这里配置下主从备份 my.ini文件的位置 mysql 8.0安装完过后没有my.ini疑惑了我好久,最后发现,配置文件在,C盘的一个隐藏文件夹里面 具体路径如下图 主库配置修改主库INI文件 在[mysqld]节点添加如下代码: 12345678#主节点(Master)配置# Binary Logging.#二进制文件存放路径log-bin=mysql-bin # Server Id.#服务器 idserver-id=1 mysql-bin这个文件夹我是创建在我的mysql安装目录的,暂时不知道有没有用 主库创建复制操作用户 这个用户主要用于连接主库,进行复制操作 创建用户mysql&gt; CREATE USER ‘需要添加的用户名‘@’从库IP地址’ IDENTIFIED WITH mysql_native_password BY ‘用户密码’;修改权限mysql&gt; GRANT REPLICATION SLAVE ON . TO ‘用户名‘@’从库IP地址’;刷新配置mysql&gt; flush privileges; 获取主节点当前binary log文件名和位置（position） mysql&gt; SHOW MASTER STATUS; 一般结果如下图: 需要记录一下 File 和 Position 的字段信息 从库配置配置INI文件 在[mysqld]节点添加如下代码: 123#从节点(Master)配置# Server Id.server-id=2 从库设置主库参数 mysql&gt;CHANGE MASTER TO MASTER_HOST=’主库IP地址’, MASTER_USER=’主库刚刚添加的用户名’, MASTER_PASSWORD=’密码’, MASTER_LOG_FILE=’记录的File值’, MASTER_LOG_POS=记录的Position值(不加引号直接写数字); 开启同步 mysql&gt;start slave; 检查是否连接上主节点 mysql&gt;show slave status\\G; 这两个参数正常就OK了,接下来就是测试了 检查是否已链接上主节点，根据里面的错误信息修改配置。确保master防火墙关闭，确保my.ing里面的server-id不重复,C:\\ProgramData\\MySQL\\MySQL Server 8.0\\Data里面的auto.cnf里面的uuid不重复。","categories":[{"name":"Mysql","slug":"Mysql","permalink":"http://voidday.com/categories/Mysql/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://voidday.com/tags/Mysql/"}]},{"title":"Json Web Token 学习","slug":"Json Web Token","date":"2018-08-02T01:46:38.000Z","updated":"2018-08-31T02:18:30.940Z","comments":true,"path":"note/54405304.html","link":"","permalink":"http://voidday.com/note/54405304.html","excerpt":"Java重构项目中需要用到Token认证,在EGG框架中是阿里整合了的,在新项目中需要单独写,由于使用OAutch2.0的协议看起来有点麻烦……所以被我弃用选择使用Json Web Token来实现,下面是学习记录了,资料来至会飞的污熊","text":"Java重构项目中需要用到Token认证,在EGG框架中是阿里整合了的,在新项目中需要单独写,由于使用OAutch2.0的协议看起来有点麻烦……所以被我弃用选择使用Json Web Token来实现,下面是学习记录了,资料来至会飞的污熊 0X00 RESTful API 认证的安全考虑 在目前的项目中只有登录的接口试用了Token,但是是采用的OAutch2.0实现的,虽然是采用较为简单的password模式但是感觉实现起来还是较为复杂,在普通项目中我个人还是不推荐使用,推荐使用JTW实现Token认证 理解OAuth 2.0 JWT 0X01 JWT 的构成 如图所示,JWT解析完成过后分为3部分 HEADER,PAYLOAD,SIGNATURE 第一部分-HEADER 包括两部分信息,第一部分alg: 声明加密的算法,这里为HS256 第二部分typ: 声明类型, 这里为JWT 第二部分-PAYLOAD PAYLOAD部分是用base64对称加密进行加密PAYLOAD里面的信息,这里的信息为sub,name,iat,由于属于对称加密所以PAYLOAD一般不建议存放敏感信息 第三部分-SIGNATURE SIGNATURE是一个签证信息，这个签证信息由三部分组成： header (base64后的)payload (base64后的)secret 这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。 组成JWT 123// javascriptvar encodedString = base64UrlEncode(header) + '.' + base64UrlEncode(payload);var signature = HMACSHA256(encodedString, 'secret'); // TJVA95OrM7E2cBab30RMHrHDcEfxjoYZgeFONFh7HgQ 将这三部分用.连接成一个完整的字符串,构成了最终的jwt注意：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。 请求里面应用JWT 一般是在请求头里加入Authorization，并加上Bearer标注： 12345fetch('api/user/1', &#123; headers: &#123; 'Authorization': 'Bearer ' + token &#125;&#125;) 解析大致流程 JWT安全相关 JWT协议本身不具备安全传输功能，所以必须借助于SSL/TLS的安全通道，所以建议如下： 不应该在jwt的payload部分存放敏感信息，因为该部分是客户端可解密的部分。 保护好secret私钥，该私钥非常重要。 如果可以，请使用https协议","categories":[{"name":"JWT","slug":"JWT","permalink":"http://voidday.com/categories/JWT/"}],"tags":[{"name":"JWT","slug":"JWT","permalink":"http://voidday.com/tags/JWT/"}]},{"title":"CTF 南京邮电题库之----层层递进","slug":"CTF 南京邮电题库之----层层递进","date":"2018-07-30T11:07:22.000Z","updated":"2018-07-30T11:43:11.453Z","comments":true,"path":"note/f2aca5e2.html","link":"","permalink":"http://voidday.com/note/f2aca5e2.html","excerpt":"从现在开始每日一篇博客来记录CTF,今日题目—-层层递进","text":"从现在开始每日一篇博客来记录CTF,今日题目—-层层递进 0X00 题目概要 0X01 题目网站内容 0X02 解题过程0X00 找! 浏览了一遍F12,没法现什么有用的东西,我一度以为地址变了,怀疑的一B 0X01 Network发现奇怪的东西? 源码不管用了,我就看看网站加载了什么东西,在Network发现加载了一个404.html,内容也有点奇怪: 加载这么多的jQuery干嘛?????,定眼一看,jQuery的名字好奇怪哦什么-n -c 的哦,??????,在一看这不是flage吗?每个jQuery后面的-后面的字母拼起来就是答案 0X03 总结 感觉没有层层递进啊……….","categories":[{"name":"CTF","slug":"CTF","permalink":"http://voidday.com/categories/CTF/"}],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://voidday.com/tags/CTF/"}]},{"title":"CTF 题库记录","slug":"CTF 题库记录","date":"2018-07-27T16:21:36.000Z","updated":"2018-07-30T11:48:08.384Z","comments":true,"path":"note/f45ebcce.html","link":"","permalink":"http://voidday.com/note/f45ebcce.html","excerpt":"争取每日一更吧,题库来源实验吧","text":"争取每日一更吧,题库来源实验吧 0X01 2018-7-28(MD5注入) 这是个比较简单的一题 界面 老规矩先看页面源码吧 12345678910111213141516171819202122232425262728293031323334&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body style=\"background-color: #999\"&gt; &lt;div style=\"position:relative;margin:0 auto;width:300px;height:200px;padding-top:100px;font-size:20px;\"&gt; &lt;form action=\"\" method=\"post\"&gt; &lt;table&gt; &lt;tr&gt; 请用管理员密码进行登录~~ &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;密码：&lt;/td&gt;&lt;td&gt;&lt;input type=\"text\" name='password'&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;input type=\"submit\" name='submit' style=\"margin-left:30px;\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/form&gt; 密码错误! &lt;/div&gt; &lt;!-- $password=$_POST['password']; $sql = \"SELECT * FROM admin WHERE username = 'admin' and password = '\".md5($password,true).\"'\"; $result=mysqli_query($link,$sql); if(mysqli_num_rows($result)&gt;0)&#123; echo 'flag is :'.$flag; &#125; else&#123; echo '密码错误!'; &#125; --&gt;&lt;/body&gt;&lt;/html&gt; 页面基于PHP,源码有句sql,如下: 1SELECT * FROM admin WHERE username = 'admin' and password = '\".md5($password,true).\"'\" 存在MD5的注入情况 MD5注入 先来说一下md5()这个函数md5(string, raw) raw 可选，默认为falsetrue:返回16字符2进制格式false:返回32字符16进制格式 简单来说就是 true将16进制的md5转化为字符了,如果某一字符串的md5恰好能够产生如’or ’之类的注入语句，就可以进行注入了. 我需要把sql查询变成什么样呢?加入我正常情况输入123sql会变成什么样呢?and password = &#39;MD5加密的数据&quot;,我这里进行注入的话最简单的需要查询admin表的所有用户,但是怎么查询呢?我需要or语句,我这里找了一篇资料来自More Smoked Leet Chicken,里面提供了一个string字符串ffifdyopmd5后 : 276f722736c95d99e921722cf9ed621c,转成字符串后 ：&#39;or&#39;6&lt;trash&gt; sql语句拼接为:password = ‘XX’’or&#39;6&lt;trash&gt;6&lt;trash&gt; 在sql执行中把这节转从string转换为int到bool true 这样就完成了一个MD5的注入 2018-7-30 来自 CG-CTF 的签到题 2018-7-30 来自 CG-CTF 的MD5加密题 看代码应该是用GET请求,输入一个a的值,被MD5加密过后等于QNKCDZO加密后的值,但是a不能为QNKCDZO 第一次我想到是hash冲突,但是转过去一想hash冲突的可能太小了,最有可能的是PHP MD5函数的漏洞,一查果不其然,下面总结下: PHP在处理哈希字符串时，会利用”!=”或”==”来对哈希值进行比较，它把每一个以”0E”开头的哈希值都解释为0，所以如果两个不同的密码经过哈希以后，其哈希值都是以”0E”开头的，那么PHP将会认为他们相同，都是0。有下面一些常见的payload:QNKCDZO0e830400451993494058024219903391s878926199a0e545993274517709034328855841020s155964671a0e342768416822451524974117254469s214587387a0e848240448830537924465865611904s214587387a0e848240448830537924465865611904s878926199a0e545993274517709034328855841020s1091221200a0e940624217856561557816327384675s1885207154a0e509367213418206700842008763514s1502113478a0e861580163291561247404381396064s1885207154a0e509367213418206700842008763514s1836677006a0e481036490867661113260034900752s155964671a0e342768416822451524974117254469s1184209335a0e072485820392773389523109082030s1665632922a0e731198061491163073197128363787s1502113478a0e861580163291561247404381396064s1836677006a0e481036490867661113260034900752s1091221200a0e940624217856561557816327384675s155964671a0e342768416822451524974117254469s1502113478a0e861580163291561247404381396064s155964671a0e342768416822451524974117254469s1665632922a0e731198061491163073197128363787s155964671a0e342768416822451524974117254469s1091221200a0e940624217856561557816327384675s1836677006a0e481036490867661113260034900752s1885207154a0e509367213418206700842008763514s532378020a0e220463095855511507588041205815s878926199a0e545993274517709034328855841020s1091221200a0e940624217856561557816327384675s214587387a0e848240448830537924465865611904s1502113478a0e861580163291561247404381396064s1091221200a0e940624217856561557816327384675s1665632922a0e731198061491163073197128363787s1885207154a0e509367213418206700842008763514s1836677006a0e481036490867661113260034900752s1665632922a0e731198061491163073197128363787s878926199a0e545993274517709034328855841020 所以这道题: 2018-7-30 来自 CG-CTF 的签到题2 下面是题目: 尝试复制粘贴 点击开门错了,想一下,密码又长又可以复制?不想让我对比? ok那我先把粘贴的密码展示出来 有点小阴险啊 密码长度手动改成11,在输入个n 2018-7-30 来自 CG-CTF 题目”这不是web” 下面是题目: 下面是进去过后的样子 一开始我找的源码没发现什么,在去找了找有没有目录遍历,也没有,后来我突发奇想GIF里面保存了信息?我把图片保存下来,百度了一下GIF怎么保存string,没资料,后来我想,直接保存为txt试试?就出现了下面的情况 OK了,题目蛮有意思的,哈哈哈","categories":[{"name":"CTF","slug":"CTF","permalink":"http://voidday.com/categories/CTF/"}],"tags":[{"name":"CTF","slug":"CTF","permalink":"http://voidday.com/tags/CTF/"}]},{"title":"ubuntu16.04下启动MongoDB脚本报错ERROR: child process failed, exited with error number 1","slug":"ubuntu16.04下启动MongoDB脚本报错ERROR- child process failed, exited with error number 1","date":"2018-07-23T01:34:51.000Z","updated":"2018-07-23T08:42:10.558Z","comments":true,"path":"note/52d9d02c.html","link":"","permalink":"http://voidday.com/note/52d9d02c.html","excerpt":"第一次遇到这种问题记录下","text":"第一次遇到这种问题记录下 0X00 脚本内容 0X01 报错内容ERROR: child process failed, exited with error number 1 0X02 解决方式贼奇怪,我用root账户登陆启动,启动脚本问题解决了???原因暂时不知道 今天想到可能是日志目录我的账号没权限?","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://voidday.com/categories/Ubuntu/"}],"tags":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"http://voidday.com/tags/疑难杂症/"},{"name":"Ubuntu,","slug":"Ubuntu","permalink":"http://voidday.com/tags/Ubuntu/"}]},{"title":"ubuntu下安装mysql-5.7","slug":"ubuntu下安装mysql-5.7","date":"2018-07-19T02:19:55.000Z","updated":"2018-07-23T08:42:10.563Z","comments":true,"path":"note/d7727b94.html","link":"","permalink":"http://voidday.com/note/d7727b94.html","excerpt":"今天看我盟哥在搭建到耍我也耍一哈,顺便记录下","text":"今天看我盟哥在搭建到耍我也耍一哈,顺便记录下 0X00 第一步 sudo apt-get install mysql-server会安装以下依赖:apparmormysql-client-5.7mysql-commonmysql-servermysql-server-5.7mysql-server-core-5.7 无需再安装mysql-client等,安装过程会提示输入用户名,输入完毕回车,如下 输入完毕会提示输入用户密码,输入完毕回车,如下 0X01 安装完成 查看是mysql是否占用端口,处于 LISTEN 说明就OK了(类似于看是否启动) ‘sudo netstat -tap | grep mysql’ 0X02 localhost登录mysql服务 本机登录测试 (这里root是你的用户名) ‘mysql -u root -p’ 0X03 常见命令 开启mysql service mysql start关闭mysql service mysql stop重启mysql service mysql restart 0X04 常用配置1. 允许远程访问 首先修改文件 sudo vi /etc/mysql/mysql.conf.d/mysqld.cnf 需要修改的地方在第43行左右点击i进入编辑模式,编辑完按esc退出编辑模式,在按shift加冒号(shift + :),输入wq保存退出 保存退出,执行授权命令：进入mysql服务mysql -u root -p, 执行grant all on *.* to root@&#39;%&#39; identified by &#39;你的密码&#39; with grant option;(记住复制分号,意思是赋予任何主机访问数据库权限)刷新flush privileges;(记住复制分号) 然后执行quit命令退出mysql服务，执行如下命令重启mysql： service mysql restart #重启mysql可能会叫你输入用户密码(不是mysql的密码,你是登录服务器的密码) 测试连接 2. 添加远程用户 输入以下命令 mysql -u root -p #进入mysqlgrant all on *.* to pock@&#39;%&#39; identified by &#39;123456&#39;; #添加一个用户名为pock 密码为123456的用户flush privileges; #刷新配置输入quit退出mysqlservice mysql restart #重启mysql 如果遇到新添加的远程用户无法登录的情况进入mysql输入以下命令 grant all privileges on . to root@’%’ identified by “root用户的密码”; 修改远程用户密码 mysql -u root -p #进入mysqluse mysql; 使用用户表update user set password=password(&#39;新密码&#39;) where user=&#39;需要修改的用户&#39;;flush privileges;刷新配置 0X05 安全配置防火墙不多说配置账号权限 禁止root账号远程登录 update user set host = &quot;localhost&quot; where user = &quot;root&quot; and host= &quot;%&quot;; flush privileges; 禁止项目用户的账号远程登录（项目配置文件） update user set host = &quot;localhost&quot; where user = &quot;web_user&quot; and host= &quot;%&quot;;flush privileges; 同时绑定该账号只允许内网访问（如内网IP：172.19.230.1） update user set host = &quot;172.19.230.1&quot; where user = &quot;web_user&quot; and host= &quot;localhost&quot;;flush privileges; 通过内网连接数据 mysql -h 172.19.230.1 -u web_user -p 针对远程需要登录的可以重新新建一个用户用于远程连接数据库 grant all on *.* to yc_user@&#39;%&#39; identified by &#39;yc123456&#39; with grant option;flush privileges; 说一下where user = “web_user” web_user的权限分类 1.root 禁止远程访问2.web_user 只允许内网访问，该用户暴露在项目代码中3.yc_user 可以远程访问，该用户不应该暴露在项目代码中 0X06 服务管理 不建议用chkconfig,这里使用`sysv-rc-conf 安装sysv-rc-conf sudo apt-get install sysv-rc-conf 直接加入启动程序，例如把 /etc/init.d/mysql 加入到系统自动 启动列表中： sudo sysv-rc-conf mysql on #开启sudo sysv-rc-conf mysql off #关闭 直接使用 sysv-rc-conf 来管理安装命令如下: sudo sysv-rc-conf 界面如下: 介绍下快捷键 使用空格键可以在on和off之间切换+号可以启动服务-号可以停止服务ctrl + n 翻到下一页ctrl + p 翻到上一页h可以查看帮助q退出 介绍下级别(运行级别的详情不太懂) 0 停机 1 单用户，Does not configure network interfaces, start daemons, or allow non-root logins 2 多用户，无网络连接 Does not configure network interfaces or start daemons 3 多用户，启动网络连接 Starts the system normally. 4 用户自定义 5 多用户带图形界面 6 重启","categories":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://voidday.com/categories/Ubuntu/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://voidday.com/tags/Ubuntu/"}]},{"title":"无工具破解开机密码","slug":"无工具破解开机密码","date":"2018-07-18T08:13:16.000Z","updated":"2018-07-23T08:42:10.604Z","comments":true,"path":"note/dcc9c25d.html","link":"","permalink":"http://voidday.com/note/dcc9c25d.html","excerpt":"经常忘记怎么无工具这里整理下","text":"经常忘记怎么无工具这里整理下 0X00 Win7下绕过 win7开机绕圈圈的时候一直按住开机键,强制关机 重复启动直到出现启动修复的界面 点启动修复 等待修复失败,点击查看问题详情 点击下面的 然后打开 到windows/System32目录下(记住选择文件类型为所有)把Utilman重命名为Utilman1,在把cmd重命名为Utilman 依次关闭窗口(记得点取消) 开机开机过后按5次shift弹出cmd输入 net user 你想要修改的用户名 你想要的密码 0X01 Win10下绕过 win10开机绕圈圈的时候一直按住开机键,强制关机 重复强制关机一直到自动修复 出现下图时，选择“疑难解答”: 出现下图时，选择“高级选项”: 出现下图时，选择“命令提示符”： 进入CMD 进入CMD过后应该是在X盘,一个隐藏盘吧应该是 直接输入 c:,进入C盘 输入cd Windows\\System32 进入System32目录 输入ren sethc.exe AAA.exe 把沾滞建重命名 输入ren cmd.exe sethc.exe 把cmd替换为sethc.exe 退出重启 开机开机过后按5次shift弹出cmd输入 net user 你想要修改的用户名 你想要的密码","categories":[{"name":"杂项","slug":"杂项","permalink":"http://voidday.com/categories/杂项/"}],"tags":[{"name":"杂项","slug":"杂项","permalink":"http://voidday.com/tags/杂项/"}]},{"title":"SQL注入","slug":"SQL注入的总结","date":"2018-07-04T04:52:31.000Z","updated":"2018-07-23T08:42:10.426Z","comments":true,"path":"note/e73517db.html","link":"","permalink":"http://voidday.com/note/e73517db.html","excerpt":"脚本小子之路,嘻嘻嘻","text":"脚本小子之路,嘻嘻嘻 0X00 扫描C段,和端口服务信息 nmap -sV -sT -Pn –open -v 地址或者IP 0X01 简单扫描端口服务信息 nmap -sV 地址或者IP 0X02 检查是否存在常见漏洞 nmap –script=vuln 地址或者IP 0X03 sqlmap默认配置 –batch 从不询问用户输入，使用所有默认配置。 0X04 sqlmap绕过WAF -v 3 –dbs –batch –tamper “space2morehash.py” space2morehash.py中可以替换space2hash.py或者base64encode.py或者charencode.py 都是编码方式 space2hash.py base64encode.py charencode.py 0X05 SQLMAP伪静态注入(1) 查找数据库 -u “http://xxx.cn/index.php/Index/view/id/40.html&quot; –dbs 0X06 SQLMAP注入点执行命令与交互写shell 此处采用的是Linux系统 sqlmap -u [url]http://192.168.159.1/news.php?id=1[/url] –os-cmd=ipconfig 获取shell sqlmap -u [url]http://192.168.159.1/news.php?id=1[/url] –os-shell 0X07 判断网站是否为伪静态 javascript:alert(document.lastModified) 1.弹出的时间和当前时间一样就是静态 2.弹出时间和当前时间不一样说明为伪静态 0X08 MSF连接数据库启用缓存系统 service postgresql start 开启数据库服务 进入MSF过后,输入db_status查看连接状态 重启MSF 0X09 sqlmapHTTP请求延迟避免WAF –delay 每次http(s)请求之间延迟时间，浮点数，单位为妙，默认无延迟，输入此参数，你会发现每个请求都会延迟3秒，当然数据库还是可以爆出来的。","categories":[{"name":"SQL注入","slug":"SQL注入","permalink":"http://voidday.com/categories/SQL注入/"}],"tags":[{"name":"SQL注入","slug":"SQL注入","permalink":"http://voidday.com/tags/SQL注入/"}]},{"title":"EGG框架在用forEach或者Map进行遍历调用async方法问题","slug":"EGG框架在用forEach或者Map进行遍历调用async方法问题","date":"2018-07-04T02:20:50.000Z","updated":"2018-07-23T08:42:10.265Z","comments":true,"path":"note/1de5170.html","link":"","permalink":"http://voidday.com/note/1de5170.html","excerpt":"EGG框架在用forEach或者Map进行遍历调用async方法问题","text":"EGG框架在用forEach或者Map进行遍历调用async方法问题 0X00 出现的情况12345//假设 newList为一个array类型,这段代码处于async中newList.forEach(x =&gt; x&#123; //这里的的await 会报错,如果不用await这里返回的y就是一个promise对象对于我这种入门的人不太好处理 var y = await this.model.show();&#125;) 0X01 我的解决方法12345//假设 newList为一个array类型,这段代码处于async中for(let i = 0; i &lt; newList.length; i++) &#123; //这里再来调用async方法,这里await方法不会报错,返回的y也是对的 var y = await this.model.show();&#125;","categories":[{"name":"EGG","slug":"EGG","permalink":"http://voidday.com/categories/EGG/"}],"tags":[{"name":"EGG","slug":"EGG","permalink":"http://voidday.com/tags/EGG/"}]},{"title":"Ubuntu常用命令","slug":"Ubuntu常用命令","date":"2018-06-19T06:03:49.000Z","updated":"2018-07-23T08:42:10.543Z","comments":true,"path":"note/fa6c14b0.html","link":"","permalink":"http://voidday.com/note/fa6c14b0.html","excerpt":"Ubuntu常用命令","text":"Ubuntu常用命令 查看磁盘空间大小命令 df -hl 查看磁盘剩余空间df -h 查看每个根路径的分区大小du -sh [目录名] 返回该目录的大小 du -sh * 查看目录下每个文件夹的大小du -sm [文件夹] 返回该文件夹总M数df –help 查看更多功能 查看文件修改时间（精确到秒） ls –full-time 删除文件 rm [参数] [文件名]-r 就是向下递归，不管有多少级目录，一并删除-f 就是直接强行删除，不作任何提示的意思 修改权限 sudo chown www:www ./ -R","categories":[{"name":"Ubuntu常用命令","slug":"Ubuntu常用命令","permalink":"http://voidday.com/categories/Ubuntu常用命令/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://voidday.com/tags/Ubuntu/"}]},{"title":"Git整理","slug":"Git整理","date":"2018-06-13T03:16:19.000Z","updated":"2018-07-23T08:42:10.277Z","comments":true,"path":"note/19a5d6d0.html","link":"","permalink":"http://voidday.com/note/19a5d6d0.html","excerpt":"记录一下容易忘记的GIT命令","text":"记录一下容易忘记的GIT命令 创建SSH Keys 输入指令，进入.ssh文件夹 cd ~/.ssh/如果提示 “ No such file or directory”，你可以手动的创建一个 .ssh文件夹即可 配置全局的name和email，这里是的你github或者bitbucket的name和email git config –global user.name “pockadmin” git config –global user.email “pockadmin@163.com“ 生成key ssh-keygen -t rsa -C “pockadmin@163.com” 连续按三次回车，这里设置的密码就为空了，并且创建了key。 打开Admin目录进入.ssh文件夹，用记事本打开id_rsa.pub，复制里面的内容添加到你github或者bitbucket ssh设置里即可","categories":[{"name":"Git","slug":"Git","permalink":"http://voidday.com/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://voidday.com/tags/Git/"}]},{"title":"MongoDB整理","slug":"MongoDB整理","date":"2018-06-13T02:16:28.000Z","updated":"2018-07-23T08:42:10.381Z","comments":true,"path":"note/f1cfe333.html","link":"","permalink":"http://voidday.com/note/f1cfe333.html","excerpt":"初学MongoDB记录下遇见的语句","text":"初学MongoDB记录下遇见的语句 数据库导出 举例 mongodump -h IP地址:MongoDB端口 -u MongoDB账户 -p MongoDB密码 -d 数据库名 -c 表名 -o /data/programs/bk/tasks.json(这里是导出的路径) -h 为需要导出的数据库地址注意加端口号 -u 为MongoDB的账号 -p 为MongoDB密码 -d 需要导出的数据在哪一个库 -c 需要导出的表名 -o 导出到哪里(可以控制导出的类型修改后缀名) 常用语句db.businesorders.find().pretty() 查看某个数据库的数据 $gte, $gt, $lte, $lt $gte 大于等于, $gt 大于, $lte小于等于, $lt小于 $match 比如说我查询之前需要根据时间筛选一次就需要这个,下面是例子 1&#123;$match : &#123;'created' : &#123;$gte : 1527782400000,$lte : 1530374400000&#125;&#125;&#125; $group 分组 { $group: { _id: , : { : }, … } } 第一个字段必须是_id,对应的就是分类的字段,field随便取 展示所有table show tables $skip,$limit 分页语句,下面是例子 1234567//$skip 跳过前面的数据 from就是前面几页的数据//$limit 和mysql一样const page = Number(pagin.page || 1);const pageSize = Number(pagin.pageSize || 10);const from = (page - 1) * pageSize;&#123; $skip: from &#125;,&#123; $limit: pageSize &#125;, $unwind 用来处理数组,下面举例 service 这里为数组结构,我分组的时候需要用某个service中的字段进行$$group,但是数组结构没办法直接用.点出来,要把数组进行处理,这里就用$unwind处理,下面是代码 1234567&#123;$unwind : '$service'&#125;,&#123;$group : &#123; _id : &#123;isHCS : '$target.isHCS' , serviceType : \"$service.category\"&#125;, price : &#123;$sum : '$price.value'&#125; &#125; &#125;]) $push 在$group的时候在集合里面放一个数组,只能push数组 123456789101112db.projectsms.aggregate([&#123;$unwind: '$phones'&#125;, &#123; $group: &#123; '_id': '$_id', 'name': &#123;$push : '$role'&#125;, 'state': &#123;$push : '$state'&#125;, 'projects': &#123;$push : '$projects._id'&#125;, 'phones': &#123;$push: '$phones'&#125; &#125; &#125;]) find语句 使用mongoose工具的时候可以使用一下方式进行过滤,不需要使用aggregate(聚合进行字段筛选): 123//params是筛选条件,&#123;name: 1, sex:1, identityNumber: 1&#125;意思是只要这些字段//默认_id字段也是返回的。如果需要去掉加上&#123;name: 1, sex:1, identityNumber: 1, _id: 0&#125;let content = await this.model.find(params,&#123;name: 1, sex:1, identityNumber: 1&#125;); updata语句1234await this.model.update( &#123;这里可以写条件和find的一样&#125; &#123;$set: &#123;'uuid': mongoose.Types.ObjectId().toString()&#125;&#125; ); count语句1await this.model.count(query); # query里面是查询条件,返回数量 $set 语句 假如有一下数据: 123456//第一条&#123;\"_id\": 1, \"imgs\": [7, 9, 2]&#125;,//第二条&#123;\"_id\": 2, \"imgs\": [17, 56, 8]&#125;,//第三条&#123;\"_id\": 3, \"imgs\": [93, 11, 534]&#125; 这里有个需求,我想要更新_id为2,把imgs节点中元素为56的跟换为99 1&gt; db.students.update(&#123;_id:2, imgs:99&#125;,&#123;$set: &#123;'imgs.$':56&#125; &#125;) 请记住，位置$操作符充当更新文档查询中第一个匹配的占位符。 假如数据变化稍微复杂,结构如下: 12345678&#123; _id: 1, imgs: [ &#123; \"header\": 12, \"body\": 32, \"food\": 67 &#125;, &#123; \"header\": 545, \"body\": 77, \"food\": 31 &#125;, &#123; \"header\": 54, \"body\": 22, \"food\": 65 &#125; ]&#125; 有个需求,我需要更新嵌套文档中_id为1中的imgs节点中的的body字段为77的那一条数据中的food改为1 1234db.xxxx.update( &#123; _id: 1, \"imgs.body\": 77 &#125;, //这一个管道为条件 &#123; $set: &#123; \"imgs.$.body\" : 77 &#125; &#125; //这一个管道为修改内容,$只会修改满足条件的第一个 还是上面的数据结构,这里又有一个需求,我需要更新嵌套文档中_id为1中的imgs节点中的的body字段为大于等于77,header小于等于500的那一条数据中的food改为1 1234db.xxxx.update( &#123; _id: 1, \"imgs\": &#123; $elemMatch : &#123;body : &#123; $gte : 77 &#125;&#125;, &#123;header : &#123; $lte : 500 &#125;&#125; &#125; &#125;, //这一个管道为条件 &#123; $set: &#123; \"imgs.$.food\" : 77 &#125; &#125; //这一个管道为修改内容,$只会修改满足条件的第一个 $elemMatch()操作符匹配多个内嵌文档的查询条件","categories":[{"name":"MongoDB整理","slug":"MongoDB整理","permalink":"http://voidday.com/categories/MongoDB整理/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"http://voidday.com/tags/MongoDB/"}]},{"title":"VI的一些常用命令","slug":"VI的一些常用命令","date":"2018-06-05T08:21:12.000Z","updated":"2018-07-23T08:42:10.553Z","comments":true,"path":"note/88a972a3.html","link":"","permalink":"http://voidday.com/note/88a972a3.html","excerpt":"VI的一些常用命令","text":"VI的一些常用命令 进入VI编辑 vi nginx.conf 输入 输入i键 跳到第一行 输入gg 删除一行 输入dd 删除所有 先输入gg到第一行,在按下d,在输入G 查找 输入 / 符号","categories":[{"name":"VI","slug":"VI","permalink":"http://voidday.com/categories/VI/"}],"tags":[{"name":"VI","slug":"VI","permalink":"http://voidday.com/tags/VI/"}]},{"title":"EGG 入门笔记","slug":"EGG 入门笔记","date":"2018-06-04T08:13:37.000Z","updated":"2018-07-23T08:42:10.273Z","comments":true,"path":"note/f0a9b556.html","link":"","permalink":"http://voidday.com/note/f0a9b556.html","excerpt":"EGG框架快速上手","text":"EGG框架快速上手 0X00 这里基于我的情况,需要快速上手 0X01 基于Egg框架的项目启动 找到目录中的package.json,点击右键show npm scripts ,然后dev run,dev run是属于在测试环境中的模式,如果在win环境下跑run的话会出现好多窗口,是因为有多少启动了多个线程,就出现了那么多的窗口 0X02 Egg基本目录结构 controller文件夹和java的一样 extent 属于可选的,可以对框架进行扩展配置,详情见框架扩展 model 是属于Egg的自定义目录规范,详情Loader API public 属于可选,放置静态文件,详情egg-static service 和java的service层一样 router.js 这个主要是路由的配置,相当于servlet配置映射的路径,这个还是比较重要的 0X03 基于RESTful风格的简单的CURD0.Egg中规定的RESTful的请求 ctx的含义 ctx - 当前请求的 Context 实例。 Egg中规定的RESTful的请求 1.简述思路 这里举一个新闻的例子,对新闻进行CURD操作,从model层开始编写,在编写controller层,最后在配置路由router.js配置出RESTful风格的接口(这里不用编写service层是因为我controller继承了一个公共类,其中有最基础的CURD方法,所以说这次上手还是感觉比较简单) 2.Model层的编写,实体的写法 下面是一个新闻的实体 12345678910111213141516'use strict';module.exports = app =&gt; &#123; const mongoose = app.mongoose; const tempSchema = new mongoose.Schema(&#123; _id: mongoose.Schema.Types.ObjectId, tile: String, //标题 content: String, //内容 intro: String, //简介 creation: Number, //创建时间 updated: Number, //更新时间 &#125;, &#123; versionKey: false, &#125;); return mongoose.model('news', tempSchema);&#125;; use strict 表示使用严格模式为什么用严格模式 消除代码运行的一些不安全之处，保证代码运行的安全； 提高编译器效率，增加运行速度； 为未来新版本的Javascript做好铺垫。 app.mongoose 调用mnogoDB插件 const tempSchema 表示mnogoDB的数据库类型?(暂时不确定,没有使用过mnogoDB) 5到10行就是字段 versionKey: false, 这个一个是个标准的写法吧 return mongoose.model(&#39;news&#39;, tempSchema); 这个可以对应到service层 3.编写Controller层 下面的新闻的controller 123456789101112131415161718192021222324252627282930313233343536373839'use strict';const CommonController = require('./commonController');class NewsController extends CommonController&#123; init() &#123; this.daoService = this.service.news; &#125; async create (ctx) &#123; await super.create(ctx); ctx.logger.debug(\"增加\"); &#125; async show (ctx) &#123; await super.show(ctx); ctx.logger.debug(\"根据ID展示\"); &#125; async index (ctx) &#123; await super.index(ctx); ctx.logger.debug(\"展示所有\"); &#125; async update (ctx) &#123; await super.update(ctx); ctx.logger.debug(\"更新\"); &#125; async destroy () &#123; await super.destroy(ctx); ctx.logger.debug(\"删除\"); &#125;&#125;module.exports = NewsController; 这里第一行也是使用严格模式,提高编译和运行速度 const CommonController = require(&#39;./commonController&#39;); 这是相当于java的导包操作,把commonController引用到当前类中(es6有class的写法) 第五行和java的class写法一样extends也一样表示继承 init() 表示初始化service层(感觉在egg框架还是es6的语法规则中,比如你要调用service层或者你要调用model层的实体的话,都是需要先进行init()进行初始化),虽然这里并没有用到新闻的service层 CRUD(那增加进行举例) 1234async create (ctx) &#123; await super.create(ctx); ctx.logger.debug(\"增加\"); &#125; async 表示使用异步的方式,await表示必须等到suoer.create的返回值在进行下一步在下面就是日志记录 4.简单介绍一下service层的写法 虽然简单的CURD我是基于现成的类进行编写的(在框架整合了简单的curd),但是在真实的业务情况中这些简单的CURD肯定是无法满足业务需求的,所以这里需要新的service层下面是例子 12345678910'use strict';const DaoService = require('./daoService');class NewsService extends DaoService&#123; init() &#123; this.model = this.ctx.model.News; &#125;&#125;module.exports = NewsService; 这里还是要先进行init()方法初始化 自定义的方法编写到daoService 中,这里进行引用应该就可以了 5.处理路由router.js 路由还是比较简单的,但是我觉得还是重要 下面是路由配置 123456789101112131415'use strict';const api = '/api/v1';/** * @param &#123;Egg.Application&#125; app - egg application */module.exports = app =&gt; &#123; const &#123; router, controller &#125; = app; router.post(api + '/surveyRecords/search', controller.surveyRecords.index); router.get(api + '/surveyRecords/exportRecord', controller.surveyRecords.exportRecord); router.resources('surveyRecords', api + '/surveyRecords', controller.surveyRecords); // 角色 router.post(api + '/roles/search', controller.roles.index); router.resources('roles', api + '/roles', controller.roles); router.resources('news', api + '/news', controller.news);&#125;; 这里一样是使用严格模式 const api = &#39;/api/v1&#39; 规定请求路径 module.exports = app =&gt; {} 标准写法 const { router, controller } = app; 这个应该也是标准写法 router.post(api + &#39;/surveyRecords/search&#39;, controller.surveyRecords.index);这个是post请求到controller文件夹下的surveyRecords.js文件中的index方法 router.resources(&#39;news&#39;, api + &#39;/news&#39;, controller.news);这个是整合了post啊get啊那些的RESTful风格,可以根据你的请求进行自动访问规定的方法 0X04接口分析(居家养老服务管理系统)0.登录接口A. 路由 router.get(api + ‘/users/login’, controller.users.login); B. Controller层代码1234567891011121314151617181920async login(ctx) &#123; //从ctx 获取当前GET请求的参数。 const user = await this.service.users.login(ctx.query.phone, ctx.query.password); if (user &amp;&amp; user.roles) &#123; user.permissions = &#123;&#125;; const allPromise = Object.keys(user.roles).map(async s =&gt; &#123; if (Array.isArray(user.roles[s])) &#123; const roles = await this.getRolesBySystem(user.roles, s); user.permissions[s] = roles; &#125; else &#123; for (const orgId of Object.keys(user.roles[s])) &#123; const roles = await this.getRolesBySystemOrg(user.roles, s, orgId); user.permissions[s] = &#123;[orgId]: roles&#125;; &#125; &#125; &#125;); await Promise.all(allPromise); &#125; ctx.body = user;&#125; if (user &amp;&amp; user.roles)user不为空,user.roles不为空 Object.keys()返回一个数组 if (Array.isArray(user.roles[s]))判断是不是数组 getRolesBySystem() C. Service层代码中的login()方法12345678async login(phone, password) &#123; const md5Pass = this.ctx.helper.md5(password); const queries = &#123; $or: [&#123;phone&#125;, &#123;shortName: phone&#125;], password: md5Pass, &#125;; return await this.model.findOne(queries).lean();&#125; 1.通过controller层的const user = await this.service.users.login(ctx.query.phone, ctx.query.password);调用到service层来 2.const md5Pass = this.ctx.helper.md5(password);调用help层(相当于java的util)进行MD5处理 3.$or是个重点,这里举一个官方例子: 1db.inventory.find( &#123; $or: [ &#123; quantity: &#123; $lt: 20 &#125; &#125;, &#123; price: 10 &#125; ] &#125; ) 意思是取出inventory(存货) 集合,条件在$or中分别有两个条件,第一个是quantity字段的值小于20或者price字段等于10,$lt的意思就是小于某个值(以后会有更详细的文章来介绍MongoDB的语法) 4.$or: [{phone}, {shortName: phone}], password: md5Pass先来大概分析这句的意思,肯定有两个条件$or中是一个条件,逗号后面是一个条件。在来分析$or中的条件,$or肯定是有两个条件,系统可以用两种账号来进行登录,第一个种是手机也就是phone字段,第二种是短命登录也就是shortName字段,{phone}相当于{phone:phone},我猜测用{phone}简写是因为在数据库的字段和这里的字段是一样的。第一个条件就分析完了，在来分析第二个条件也就是password: md5Pass这个没有$or说明这个值是一个必须满足的条件。最后在梳理一下，假如传入参数为phone=110,password=123，那么这条语句的意思是在数据库中查找phone字段等于110，或者shortName字段等于110，同时满足password字段=123 5.return await this.model.findOne(queries).lean();model层的实体都有一些默认的方法，findOne()就是其中一个，这里传入的参数就是上面拼接的MongoDB数据库语句 6.lean()这里单独说一下lean()，不加这个方法的话他返回的对象中就带有model的一些默认方法,所以要加这个方法 getRolesBySystem()方法123456async getRolesBySystem(userRoles, system) &#123; const searchParams = &#123;system, name: &#123;$in: userRoles[system]&#125;&#125;; const roles = await this.service.roles.find(searchParams); const results = roles.map(a =&gt; (&#123;[a.name]: a.permission&#125;)).reduce((a, b) =&gt; (&#123;...a, ...b&#125;), &#123;&#125;); return results;&#125; 接收到传入的userRoles数组 和system(相当于Key)","categories":[{"name":"EGG","slug":"EGG","permalink":"http://voidday.com/categories/EGG/"}],"tags":[{"name":"EGG","slug":"EGG","permalink":"http://voidday.com/tags/EGG/"}]},{"title":"Jeecg在后台进行更新内容的时候报错","slug":"Jeecg在后台进行更新内容的时候报错","date":"2018-06-04T07:33:27.000Z","updated":"2018-07-23T08:42:10.375Z","comments":true,"path":"note/3de25220.html","link":"","permalink":"http://voidday.com/note/3de25220.html","excerpt":"部署到Linux服务器在后台进行更新案例内容的时候出现下面这个错误","text":"部署到Linux服务器在后台进行更新案例内容的时候出现下面这个错误 0.环境 本机是win10,问题出现在部署到Linux服务器在后台进行更新案例内容的时候出现下面这个错误: 1.解决 百度了一下这个问题说的好像是在3.6的jeecg版本中出现过,个人感觉是windows和Linux时间格式化的问题,具体的解决方式在下面的目录中: 在这个两个bean中 12&lt;bean id=\"freemarker\" class=\"freemarker.template.Configuration\"&gt;&lt;bean id=\"freemarkerWord\" class=\"freemarker.template.Configuration\"&gt; 继续添加 1234&lt;property name=\"numberFormat\" value=\"0\"&gt;&lt;/property&gt;&lt;property name=\"dateFormat\" value=\"yyyy-MM-dd\"&gt;&lt;/property&gt;&lt;property name=\"timeFormat\" value=\"HH:mm:ss\"&gt;&lt;/property&gt;&lt;property name=\"dateTimeFormat\" value=\"yyyy-MM-dd HH:mm:ss\"&gt;&lt;/property&gt; 举一个添加完成的例子 12345678&lt;bean id=\"freemarkerWord\" class=\"freemarker.template.Configuration\"&gt; &lt;property name=\"templateLoader\" ref=\"templetLoaderWord\" /&gt; &lt;property name=\"defaultEncoding\" value=\"UTF-8\"&gt;&lt;/property&gt; &lt;property name=\"numberFormat\" value=\"0\"&gt;&lt;/property&gt; &lt;property name=\"dateFormat\" value=\"yyyy-MM-dd\"&gt;&lt;/property&gt; &lt;property name=\"timeFormat\" value=\"HH:mm:ss\"&gt;&lt;/property&gt; &lt;property name=\"dateTimeFormat\" value=\"yyyy-MM-dd HH:mm:ss\"&gt;&lt;/property&gt;&lt;/bean&gt; 2.疑问 貌似这样操作过后,以后比如我新增一个案例,或者新闻的时候,creatTime这个字段会录不进去","categories":[{"name":"Jeecg","slug":"Jeecg","permalink":"http://voidday.com/categories/Jeecg/"}],"tags":[{"name":"Jeecg","slug":"Jeecg","permalink":"http://voidday.com/tags/Jeecg/"}]},{"title":"Tomcat实时日志查看","slug":"Tomcat实时日志查看","date":"2018-05-31T01:45:19.000Z","updated":"2018-07-23T08:42:10.539Z","comments":true,"path":"note/7526a581.html","link":"","permalink":"http://voidday.com/note/7526a581.html","excerpt":"Tomcat实时日志查看","text":"Tomcat实时日志查看 进入logs日目录 tail -f catalina.out -n 可以指定展示多少行 例如 tail -n 5 catalina.out 这里展示5行","categories":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://voidday.com/categories/Tomcat/"}],"tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"http://voidday.com/tags/Tomcat/"}]},{"title":"端口被使用","slug":"端口被使用","date":"2018-05-30T09:04:42.000Z","updated":"2018-07-23T08:42:10.608Z","comments":true,"path":"note/6e54875c.html","link":"","permalink":"http://voidday.com/note/6e54875c.html","excerpt":"Linux端口被使用","text":"Linux端口被使用 netstat -anp 显示系统端口使用情况 netstat -anp|grep 40001 查看使用8080端口的程序 sudo netstat -tunlp|grep 3308 ps aux| grep tomcat 查看Tomcat进程的相关信息,包括目录信息 vi ~/.bash_history 查看历史命令 sh cataxxx.sh start 启动Tomcat (run 是DEBUG stop是停止) kill -9 进程PID","categories":[{"name":"端口占用","slug":"端口占用","permalink":"http://voidday.com/categories/端口占用/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://voidday.com/tags/Ubuntu/"},{"name":"Linux","slug":"Linux","permalink":"http://voidday.com/tags/Linux/"}]},{"title":"IDEA处理非SpringBoot的启动方法","slug":"IDEA处理非SpringBoot的启动方法","date":"2018-05-18T03:09:29.000Z","updated":"2018-07-23T08:42:10.322Z","comments":true,"path":"note/98783d64.html","link":"","permalink":"http://voidday.com/note/98783d64.html","excerpt":"记录下配置非SpringBoot的问题","text":"记录下配置非SpringBoot的问题 1. 2. 3. 4.启动在试试启动","categories":[{"name":"IDEA","slug":"IDEA","permalink":"http://voidday.com/categories/IDEA/"}],"tags":[{"name":"IDEA,","slug":"IDEA","permalink":"http://voidday.com/tags/IDEA/"},{"name":"疑难杂症","slug":"疑难杂症","permalink":"http://voidday.com/tags/疑难杂症/"}]},{"title":"Spring 的Context 上下文简单例子","slug":"Spring 的Context 上下文简单例子","date":"2018-05-18T02:37:28.000Z","updated":"2018-07-23T08:42:10.447Z","comments":true,"path":"note/43c8429b.html","link":"","permalink":"http://voidday.com/note/43c8429b.html","excerpt":"Spring 的Context 上下文简单例子(技术不够啊,现在还没理解)","text":"Spring 的Context 上下文简单例子(技术不够啊,现在还没理解) 前言简单例子便于以后使用,这里Man注入是采用构造器注入,需要QQcar类,所以在XML配置的时候使用的constructor-arg,来指定构造器需要的东西 1.基于xml的配置方式12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.2.xsd\"&gt; &lt;bean id=\"man\" class=\"spring.chapter1.domain.Man\"&gt; &lt;constructor-arg ref=\"qqCar\" /&gt; &lt;/bean&gt; &lt;bean id=\"qqCar\" class=\"spring.chapter1.domain.QQCar\"/&gt;&lt;/beans&gt; 配置完成后 1234567891011public class Test &#123; public static void main(String[] args) &#123; //加载项目中的spring配置文件到容器// ApplicationContext context = new ClassPathXmlApplicationContext(\"resouces/applicationContext.xml\"); //加载系统盘中的配置文件到容器(两种方式都能获取) ApplicationContext context = new FileSystemXmlApplicationContext(\"E:/Spring/applicationContext.xml\"); //从容器中获取对象实例 Man man = context.getBean(Man.class); man.driveCar(); &#125;&#125; 基于注解式123456789101112//同xml一样描述bean以及bean之间的依赖关系@Configurationpublic class ManConfig &#123; @Bean public Man man() &#123; return new Man(car()); &#125; @Bean public Car car() &#123; return new QQCar(); &#125;&#125; 配置完成 123456789public class Test &#123; public static void main(String[] args) &#123; //从java注解的配置中加载配置到容器 ApplicationContext context = new AnnotationConfigApplicationContext(ManConfig.class); //从容器中获取对象实例 Man man = context.getBean(Man.class); man.driveCar(); &#125;&#125;","categories":[{"name":"ApplicationContext","slug":"ApplicationContext","permalink":"http://voidday.com/categories/ApplicationContext/"}],"tags":[{"name":"spring,","slug":"spring","permalink":"http://voidday.com/tags/spring/"},{"name":"Context上下文","slug":"Context上下文","permalink":"http://voidday.com/tags/Context上下文/"}]},{"title":"HEXO博客搭建的坑","slug":"HEXO博客搭建的坑","date":"2018-05-18T02:37:28.000Z","updated":"2018-07-23T08:42:10.310Z","comments":true,"path":"note/254c3d71.html","link":"","permalink":"http://voidday.com/note/254c3d71.html","excerpt":"记录下第二次搭建博客的流程","text":"记录下第二次搭建博客的流程 前景 原来的博客换了电脑就没法更新了,很麻烦,这里我使用分支的方式进行部署,顺便记录一下自己遇到问题 0X00 环境配置 配置nodejs 安装git命令客户端 配置git,命令为 git config --global user.name &quot;你的github名字&quot; , git config --global user.email &quot;你的github邮箱&quot; 0X01 GitHub仓库创建 第一步 第二步 注意这里名字要用自己的GitHub用户名加.github.io,才能让GitHub自动给你分配githubpage 第三步 在仓库里面随便创建一个REMDME文件,方便修改分支 第四步 新建一个分支 设置为默认分支 0X02 配置HEXO 第一步 使用git把你的默认分支clone下来(直接复制地址clone肯定是你的默认分支) 第二步 进入项目目录在git用使用hexo init blog 把blog文件中的东西复制到你的项目目录去(如果blog文件中有.git的话就删除在复制就完了) 第三步 使用github的windows客户端把修改提交到分支 0X03 部署 ‘hexo g’ hexo s //启动本地服务,方便看效果 hexo d //提交到分支了,然后master分支就合并了 上一步可能存在一些问题,我平常更新是结合github的Windows客户端进行提交,也就是我hexo s启动过后看效果,ok的话我就直接用客户端进行上传,上传完成过后访问线上网站并不会更新,我需要点击 这个按钮才会更新线上的(原因我没研究,怪我github用的太少) 0X04 遇到的问题 ERROR Plugin load failed: hexo-server解决: sudo npm install hexo-server hexo-renderer相关的错误解决: npm install hexo-renderer-ejs --save npm install hexo-renderer-stylus --save npm install hexo-renderer-marked --save 这个时候再重新生成静态文件，命令： hexo generate （或hexo g） 启动本地服务器： hexo server （或hexo s）","categories":[{"name":"HEXO","slug":"HEXO","permalink":"http://voidday.com/categories/HEXO/"}],"tags":[{"name":"HEXO","slug":"HEXO","permalink":"http://voidday.com/tags/HEXO/"}]},{"title":"我的IDEA常用插件","slug":"我的IDEA常用插件","date":"2018-02-28T01:45:00.000Z","updated":"2018-07-23T08:42:10.613Z","comments":true,"path":"note/9ea03639.html","link":"","permalink":"http://voidday.com/note/9ea03639.html","excerpt":"记录下使用IDEA开发下常用的插件","text":"记录下使用IDEA开发下常用的插件 CodeGlance 代码预览 Alibaba Java Coding Guidelines 代码审查,根据阿里巴巴Java开发守则 grep-console 日志颜色区分,结合log4j activate-power-mode 写代码时的动画效果 Maven Helper 一旦安装了Maven Helper插件，只要打开pom文件，就可以打开该pom文件的Dependency Analyzer视图（在文件打开之后，文件下面会多出这样一个tab），进入Dependency Analyzer视图之后有三个查看选项，分别是Conflicts(冲突)、All Dependencies as List(列表形式查看所有依赖)、All Dependencies as Tree(树结构查看所有依赖)。并且这个页面还支持搜索。很方便！并且使用该插件还能快速的执行maven命令。 FindBugs 查找BUG Jrebel 热部署插件 类注释模板 File and Code Templates 中设置class 添加模板 12345678910/*** @program: $&#123;PROJECT_NAME&#125;** @description: $&#123;description&#125;** @author: lq** @create: $&#123;YEAR&#125;/$&#123;MONTH&#125;/$&#123;DAY&#125;**/","categories":[{"name":"IDEA","slug":"IDEA","permalink":"http://voidday.com/categories/IDEA/"}],"tags":[{"name":"IDEA","slug":"IDEA","permalink":"http://voidday.com/tags/IDEA/"}]},{"title":"LinkedList,学习总结","slug":"LinkedList,学习总结","date":"2018-01-22T02:46:07.000Z","updated":"2018-07-23T08:42:10.385Z","comments":true,"path":"note/b0c11e4a.html","link":"","permalink":"http://voidday.com/note/b0c11e4a.html","excerpt":"学习链表结构的记录而已","text":"学习链表结构的记录而已 前言 队列、堆栈与数组、链表的关系与区分 1.先要搞明白两个东西,数据结构,和数据存储结构 数据结构：是指相互之间存在一种或多种特定关系的数据元素的 集合。听起来是不是很抽象，简单理解：数据结构就是描述对象间逻辑关系的学科。比如：队列就是一种先进先出的逻辑结构，栈是一种先进后出的逻辑结构，家谱 是一种树形的逻辑结构！（初学数据结构的时候很不理解为什么有“栈”这个东西；队列很容易理解—无论购物就餐都需要排队；栈可以认为就是个栈道— 只允许一个人通过的小道，而且只能从一端进入，然后再从这端返回，比如你推了个箱子进去啦，第二个人也推个箱子进去，此时只能等后进来的这个人拉着箱子出 去后，你才能退出。） 数据存储结构：它是计算机的一个概念，简单讲，就是描述数据在计算机中存储方式的学科；常用的数据存储 方式就两种：顺序存储，非顺序存储！顺序存储就是把数据存储在一块连续的存储介质（比如硬盘或内存）上—-举个例子：从内存中拿出第100个字节到 1000个字节间的连续位置，存储数据；数组就是典型的顺序存储！非顺序存储就是各个数据不一定存在一个连续的位置上，只要每个数据知道它前面的数据和后 面的数据，就能把所有数据连续起来啦；链表就是典型的非顺序存储啦！ 队列、栈是线性数据结构的典型代表，而数组、链表是常用的两种数据存储结构；队列和栈均可以用数组或链表的存储方式实现它的功能！ 双向链表 LinkedList它的每个数据结点中都有两个指针，分别指向直接后继和直接前驱。所以，从双向链表中的任意一个结点开始，都可以很方便地访问它的前驱结点和后继结点。这种叫做双向链表也叫双链表 LinkedList LinkedList中定义了3个属性first,last,size,如下: 123456789101112131415transient int size = 0;/** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */transient Node&lt;E&gt; first;/** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */transient Node&lt;E&gt; last; first表示上一个节点的信息 last表示下一个节点的信息 size表示双向链表中节点实例的个数 节点 LinkedList是采用节点Node方式把前后两个节点关联起来,变成链表,在LinkedList的源码中有个节点的内部类 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; LinkedList之所以是双向链表就是因为Node节点中的next和prev两个参数把链串联起来 next:保存下一个节点的信息 prev:保存上一个节点的信息 element:节点的具体内容(相当于业务数据) LinkedList中的remove()方法分析1234567/*** 返回泛型*/public E remove() &#123; //调用removeFirst方法 return removeFirst();&#125; removeFirst() 123456789101112131415/** * 删除并返回此列表中的第一个元素。 * * @return 列表中的第一个元素。 * @throws 如果这个列表是空的，则抛出NoSuchElementException。 */public E removeFirst() &#123; //把第一个元素拿出来 final Node&lt;E&gt; f = first; //如果为空就报异常 if (f == null) throw new NoSuchElementException(); //进入unlinkFirst(f) return unlinkFirst(f);&#125; unlinkFirst(f) 1234567891011121314151617181920212223242526272829/** * 取消链接非空的第一个节点f。 */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; //从需要移除的元素中把业务数据拿出来 final E element = f.item; //从需要移除的元素中把下一个节点的信息拿出来 //现在next节点就变成了 final Node&lt;E&gt; next = f.next; //把需要移除的节点的数据设为空 f.item = null; //把需要移除的元素的下一个节点设置为空,利用GC回收 f.next = null; // help GC //然后把这个链表的第一个设置为next节点 first = next; //判断f节点的下一个节点是否为空,为空的话,这个链表的下个节点也就为空,整个双向链表就为空了 if (next == null) last = null; else //不为空的话,现在next节点就变成了,整个双向链表的第一个节点,所以next节点的上一个节点就为空了 next.prev = null; //双向链表的长度减少 size--; //次数这个是??暂时没弄明白 modCount++; //返回f节点的业务数据 return element; &#125; LinkedList中的add(E e)方法分析1234567891011/** *将指定的元素追加到列表的末尾。 *该方法相当于#addLast。 * @param e 要添加到此列表中的元素。 * @return true */public boolean add(E e) &#123; //调用linkLast(e)方法 linkLast(e); return true;&#125; linkLast(e) 12345678910111213141516171819/** * 链接e作为最后一个元素。 */void linkLast(E e) &#123; //让last最后一个节点赋值给l final Node&lt;E&gt; l = last; //调用内部类Node节点的构造方法 final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //让最后一个节点last的值变为newNode last = newNode; //如果最后一个节点为空,就让newNode变成第一个节点first if (l == null) first = newNode; else //不为空的话,让最后一个节点的下一个节点设置为newNode l.next = newNode; size++; modCount++;&#125; 内部类class Node&lt;E&gt;: 12345678910111213private static class Node&lt;E&gt; &#123; E item; //节点业务数据信息,使用泛型 Node&lt;E&gt; next; //当前节点的下一个节点信息 Node&lt;E&gt; prev; //当前节点的上一个节点信息 //在new一个Node时,比如add(e) 方法是保存到双向链表的尾部,肯定需要上一个节点的信息 //参数信息prev:上一个节点;element:当前new的节点所需要的业务数据;next:下一个节点的信息 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; //1.把需要的业务数据,添加到节点中的item中 this.next = next; //2.填写下一个节点信息,可以为null,比如在add()方法中就体现了 this.prev = prev; //3.因为这是一个新的节点所以需要指定上一个节点 &#125;&#125; LinkedList中的get(int index)方法分析12345678910111213/** * 返回列表中指定位置的元素。 * * @param index 返回元素的索引。 * @return the 元素在列表中的指定位置。 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; //第一步调用checkElementIndex(index)方法检查下标是否越界 checkElementIndex(index); //第二步,调用node(index)方法 return node(index).item;&#125; 第一步检查下标越界情况 checkElementIndex(index)方法,其中有个构造异常信息的方法 1234567891011121314/** * Constructs an IndexOutOfBoundsException detail message. * Of the many possible refactorings of the error handling code, * this \"outlining\" performs best with both server and client VMs. */private String outOfBoundsMsg(int index) &#123; return \"Index: \"+index+\", Size: \"+size;&#125;private void checkElementIndex(int index) &#123; //这里调用了isElementIndex(index)方法,判断下标是否越界,越界抛出异常 if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; - `isElementIndex(index)`方法 1234567/** * 说明参数是否为现有元素的索引。 */private boolean isElementIndex(int index) &#123; //判断是否下标越界,返回true或者false return index &gt;= 0 &amp;&amp; index &lt; size;&#125; 第二步,确定元素位置 node(index)方法 123456789101112131415161718192021/*** 返回指定元素索引中的(非空)节点。*/Node&lt;E&gt; node(int index) &#123;// assert isElementIndex(index);//这里使用的是二分查找法,如果size右移1位,代表size的一半大小;这种情况下如果,元素的下标index小于的元素的一半说明,元素的位置在前半截,所以从firsy开始遍历if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; //这里遍历到指定元素的前一位停止,然后取出前一位的下一位,得到指定元素,节约性能 for (int i = 0; i &lt; index; i++) x = x.next; return x;&#125; else &#123; Node&lt;E&gt; x = last; //这里同理,从最后一个开始遍历,遍历的下标i-1,如果i大于了,指定元素的下标说明,i这个节点的前一个就是指定的元素,所以用x.prev,就可以了 for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; LinkedList中的set(int index, E element)方法分析1234567891011121314151617181920/** * 将元素替换为该列表中指定位置的元素。 * * @param 要替换的元素的索引索引。 * @param 要存储在指定的位置和元素。 * @return 在指定位置之前的元素的业务数据。 * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; //调用检查下标是否越界的方法,和get(Int index)方法一样 checkElementIndex(index); //取出指定下标位置的节点node(index)方法和上面一样 Node&lt;E&gt; x = node(index); //把节点x的老数据取出来 E oldVal = x.item; //把新数据给x节点 x.item = element; //返回x节点的老数据 return oldVal;&#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://voidday.com/categories/数据结构/"}],"tags":[{"name":"LinkedList","slug":"LinkedList","permalink":"http://voidday.com/tags/LinkedList/"}]},{"title":"HashMap的负载因子","slug":"HashMap的负载因子","date":"2018-01-22T01:56:00.000Z","updated":"2018-07-23T08:42:10.305Z","comments":true,"path":"note/726001da.html","link":"","permalink":"http://voidday.com/note/726001da.html","excerpt":"学习数据结构的笔记","text":"学习数据结构的笔记 在使用LinkedHashMap时,如下: 12345public class test &#123; public static void main(String[] args) &#123; Map&lt;String, Object&gt; map = new LinkedHashMap&lt;String, Object&gt;(); &#125;&#125; 发现LinkedHashMap中的构造方法 1234public LinkedHashMap() &#123; super(); accessOrder = false; &#125; 发现调用的父类HashMap其中的一个构造方法 123public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; 其中的DEFAULT_LOAD_FACTOR常量被设定为0.75,如下 1static final float DEFAULT_LOAD_FACTOR = 0.75f; 这就是HashMap负载因子的默认值 而HashMap的另一个构造函数: 123456789101112131415161718192021/** * Constructs an empty &lt;tt&gt;HashMap&lt;/tt&gt; with the specified initial * capacity and load factor. * * @param initialCapacity the initial capacity * @param loadFactor the load factor * @throws IllegalArgumentException if the initial capacity is negative * or the load factor is nonpositive */ public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); &#125; 其中有两个参数initialCapacity和loadFactor initialCapacity表示map的初始化容量，initialCapacity &gt; MAXIMUM_CAPACITY，表明map的最大容量是1&lt;&lt;30,也就是1左移30位，每左移一位乘以2，所以就是1*2^30=1073741824 loadFactor是map的负载因子,loadFactor &lt;= 0 || Float.isNaN(loadFactor),表明负载因子要大于0，且是非无穷大的数字 负载因子为什么会影响HashMap的性能? 这里借用sxlzs_博主的解释 我们都知道有序数组存储数据，对数据的索引效率都很高，但是插入和删除就会有性能瓶颈（回忆ArrayList）， 链表存储数据，要一次比较元素来检索出数据，所以索引效率低，但是插入和删除效率高（回忆LinkedList）， 两者取长补短就产生了哈希散列这种存储方式，也就是HashMap的存储逻辑. 而负载因子表示一个散列表的空间的使用程度，有这样一个公式：initailCapacity*loadFactor=HashMap的容量。 所以负载因子越大则散列表的装填程度越高，也就是能容纳更多的元素，元素多了，链表大了，所以此时索引效率就会降低。 反之，负载因子越小则链表中的数据量就越稀疏，此时会对空间造成烂费，但是此时索引效率高。 如何科学的设置initailCapacity,loadFactor的值: HashMap有三个构造函数，可以选用无参构造函数，不进行设置。默认值分别是16和0.75 官方的建议是initailCapacity设置成2的n次幂，laodFactor根据业务需求，如果迭代性能不是很重要，可以设置大一下。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"http://voidday.com/categories/数据结构/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://voidday.com/tags/Java/"},{"name":"HashMap","slug":"HashMap","permalink":"http://voidday.com/tags/HashMap/"}]},{"title":"JavaFx苦逼之路","slug":"JavaFx爬坑之旅","date":"2018-01-12T01:42:00.000Z","updated":"2018-07-23T08:42:10.359Z","comments":true,"path":"note/69cc9e87.html","link":"","permalink":"http://voidday.com/note/69cc9e87.html","excerpt":"啊啊啊,JavaFX贼难玩,不喜欢","text":"啊啊啊,JavaFX贼难玩,不喜欢 前言目前我能用javafx做的东西都很少,还跟在大佬屁股后面学习.说不定写着写着就脱坑停更! 绑定tableView 需求是绑定几个测试参数到tableView下如图 结构为:tabPane -&gt; Tab -&gt; tableView -&gt; 若干个TableColumn 第一步先设置fx:idtableView上肯定需要fx:id,然后在给每一列绑定fx:id,如下图 第二步,编写相关联的实体由于我的tableview中显示的数据封装在了实体类中,所以这里我们需要先定义实体,实体的定义如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137import javafx.beans.property.DoubleProperty;import javafx.beans.property.IntegerProperty;import javafx.beans.property.SimpleDoubleProperty;import javafx.beans.property.StringProperty;/** * 限价委托实体类 */public class LimitEntrustEntity extends Commission&#123; private DoubleProperty orderState = new SimpleDoubleProperty(); //已成交数量 private DoubleProperty priceOfOrder = new SimpleDoubleProperty(); //成交均价 private DoubleProperty gvm = new SimpleDoubleProperty(); //成交总额 public LimitEntrustEntity(DoubleProperty orderState, DoubleProperty priceOfOrder, DoubleProperty gvm) &#123; this.orderState = orderState; this.priceOfOrder = priceOfOrder; this.gvm = gvm; &#125; public LimitEntrustEntity() &#123; &#125; public double getOrderState() &#123; return orderState.get(); &#125; public DoubleProperty orderStateProperty() &#123; return orderState; &#125; public void setOrderState(double orderState) &#123; this.orderState.set(orderState); &#125; public double getPriceOfOrder() &#123; return priceOfOrder.get(); &#125; public DoubleProperty priceOfOrderProperty() &#123; return priceOfOrder; &#125; public void setPriceOfOrder(double priceOfOrder) &#123; this.priceOfOrder.set(priceOfOrder); &#125; public double getGvm() &#123; return gvm.get(); &#125; public DoubleProperty gvmProperty() &#123; return gvm; &#125; public void setGvm(double gvm) &#123; this.gvm.set(gvm); &#125; @Override public double getCommissionQty() &#123; return super.getCommissionQty(); &#125; @Override public DoubleProperty commissionQtyProperty() &#123; return super.commissionQtyProperty(); &#125; @Override public void setCommissionQty(double commissionQty) &#123; super.setCommissionQty(commissionQty); &#125; @Override public double getCommissionTime() &#123; return super.getCommissionTime(); &#125; @Override public DoubleProperty commissionTimeProperty() &#123; return super.commissionTimeProperty(); &#125; @Override public void setCommissionTime(double commissionTime) &#123; super.setCommissionTime(commissionTime); &#125; @Override public double getCommissionPrice() &#123; return super.getCommissionPrice(); &#125; @Override public DoubleProperty commissionPriceProperty() &#123; return super.commissionPriceProperty(); &#125; @Override public void setCommissionPrice(double commissionPrice) &#123; super.setCommissionPrice(commissionPrice); &#125; @Override public int getState() &#123; return super.getState(); &#125; @Override public IntegerProperty stateProperty() &#123; return super.stateProperty(); &#125; @Override public void setState(int state) &#123; super.setState(state); &#125; @Override public String getOrderSource() &#123; return super.getOrderSource(); &#125; @Override public StringProperty orderSourceProperty() &#123; return super.orderSourceProperty(); &#125; @Override public void setOrderSource(String orderSource) &#123; super.setOrderSource(orderSource); &#125;&#125; 这里我继承了父类,父类如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.yczr.threebody.pc.entity;import javafx.beans.property.*;import java.io.Serializable;public class Commission implements Serializable &#123; private DoubleProperty commissionQty = new SimpleDoubleProperty(); //委托数量 2 private DoubleProperty commissionTime = new SimpleDoubleProperty(); //委托时间 2// private DoubleProperty triggerPrice; //触发价格 1 private DoubleProperty commissionPrice = new SimpleDoubleProperty(); //委托价格 2// private TradeStatus realTriggerPrice; //真实触发价 1 private IntegerProperty state = new SimpleIntegerProperty(); //状态 2 private StringProperty orderSource = new SimpleStringProperty(); //订单来源 2 public double getCommissionQty() &#123; return commissionQty.get(); &#125; public DoubleProperty commissionQtyProperty() &#123; return commissionQty; &#125; public void setCommissionQty(double commissionQty) &#123; this.commissionQty.set(commissionQty); &#125; public double getCommissionTime() &#123; return commissionTime.get(); &#125; public DoubleProperty commissionTimeProperty() &#123; return commissionTime; &#125; public void setCommissionTime(double commissionTime) &#123; this.commissionTime.set(commissionTime); &#125;// public double getTriggerPrice() &#123;// return triggerPrice.get();// &#125;//// public DoubleProperty triggerPriceProperty() &#123;// return triggerPrice;// &#125;//// public void setTriggerPrice(double triggerPrice) &#123;// this.triggerPrice.set(triggerPrice);// &#125; public double getCommissionPrice() &#123; return commissionPrice.get(); &#125; public DoubleProperty commissionPriceProperty() &#123; return commissionPrice; &#125; public void setCommissionPrice(double commissionPrice) &#123; this.commissionPrice.set(commissionPrice); &#125; public int getState() &#123; return state.get(); &#125; public IntegerProperty stateProperty() &#123; return state; &#125; public void setState(int state) &#123; this.state.set(state); &#125; public String getOrderSource() &#123; return orderSource.get(); &#125; public StringProperty orderSourceProperty() &#123; return orderSource; &#125; public void setOrderSource(String orderSource) &#123; this.orderSource.set(orderSource); &#125;&#125; 顺便说一下这里遇到的坑!!!!! 定义需要绑定的值时,属性还是用的以前的类型,比如Double类型还是用的Double,但是在javafx中Double变为了javafx中的封装类型DoubleProperty,其它的数据类型应该也是这样; 实体类我用的随机数进行赋值,代码如下: 1234567891011121314151617181920212223public static Double getRandom(int max)&#123; double v = new Random(max).nextDouble(); return v; &#125; public static Double getRandom()&#123; Double random = getRandom(1000); return random; &#125; public static LimitEntrustEntity getLeEntity() &#123; LimitEntrustEntity leEntity = new LimitEntrustEntity(); leEntity.setCommissionPrice(getRandom()); leEntity.setCommissionQty(getRandom()); leEntity.setCommissionTime(getRandom()); leEntity.setGvm(getRandom()); leEntity.setOrderSource(getRandom().toString()); leEntity.setOrderState(getRandom()); leEntity.setPriceOfOrder(getRandom()); leEntity.setState(getRandom().intValue()); return leEntity; &#125; 其中的坑是真的多!,我没有没父类Commission中的属性设置默认值,导致加载数据时为空 第三步,在代码中与fx:id绑定虽然在fxml文件中设置了fx:id,但是在实际的程序中并没有做任何相关联的绑定,所以这一步就需要进行相关的绑定; 定义数据源 1private ObservableList&lt;TradeOverviewEntity&gt; exchangeData = FXCollections.observableArrayList(); 绑定TableView 12@FXMLprivate TableView&lt;TradeOverviewEntity&gt; exTable; 绑定列TableColumn 12345678@FXMLprivate TableColumn&lt;TradeOverviewEntity, String&gt; coinName;@FXMLprivate TableColumn&lt;TradeOverviewEntity, Number&gt; exPrice;@FXMLprivate TableColumn&lt;TradeOverviewEntity, Number&gt; exMaxPrice; //..........省略其它列 加载数据 前面虽然绑定了数据源,但是并没有进行实际的赋值,下面先把值和列对应上 12345678910 private void initBean()&#123; lpwtTime.setCellValueFactory(cellData -&gt; cellData.getValue().commissionTimeProperty()); //委托时间 plNumber.setCellValueFactory(cellData -&gt; cellData.getValue().commissionQtyProperty()); //委托数量 plDeal.setCellValueFactory(cellData -&gt; cellData.getValue().orderStateProperty()); //已成交 plPrice.setCellValueFactory(cellData -&gt; cellData.getValue().commissionPriceProperty()); //委托价格 plPrice2.setCellValueFactory(cellData -&gt; cellData.getValue().priceOfOrderProperty()); //成交均价(QC) plTotal.setCellValueFactory(cellData -&gt; cellData.getValue().commissionTimeProperty()); //成交总额(QC) plState.setCellValueFactory(cellData -&gt; cellData.getValue().stateProperty()); //状态 plSource.setCellValueFactory(cellData -&gt; cellData.getValue().orderSourceProperty()); //状态&#125; 对数据进行赋值 123456private void loadData()&#123; //随机生成5个订单 for (int i = 0; i &lt; 5; i++) &#123; limitEntrusData.add(BeanUtils.getLeEntity()); &#125; &#125; 初始化加载数据 1234567@FXMLprivate void initialize() &#123; initBean(); loadData(); lpTable.setItems(limitEntrusData);&#125; 效果 监听TextField变化目的是为了完成界面简单的密码强度判断,如下界面 绑定fxid 其它的fxid就不一一绑定了 编写监听方法123456789101112131415161718192021public void testyy() &#123; password.textProperty().addListener(new ChangeListener&lt;String&gt;() &#123; @Override public void changed(ObservableValue&lt;? extends String&gt; observable, String oldValue, String newValue) &#123; //下面是逻辑处理部分 if (password.getText().equals(\"\") || password.getText().length() &lt; 1) &#123; pwIntensity.setText(\"登录密码不能为空\"); &#125; else &#123; String intensity = null; if (password.getText().length() &gt; 5) &#123; intensity = \"强\"; &#125; else if (password.getText().length() &lt; 5) &#123; intensity = \"弱\"; &#125; else &#123; intensity = \"极强\"; &#125; pwIntensity.setText(\"密码强度\" + intensity); &#125; &#125; &#125;);&#125; 调用监听监听需要在页面初始化的时候就进行加载,所以在initialize()中吊起 1234@FXMLprivate void initialize() &#123; testyy();&#125; 效果","categories":[{"name":"JavaFx","slug":"JavaFx","permalink":"http://voidday.com/categories/JavaFx/"}],"tags":[{"name":"JavaFx","slug":"JavaFx","permalink":"http://voidday.com/tags/JavaFx/"}]},{"title":"Spring Cloud初体验","slug":"Spring Cloud初体验","date":"2017-12-25T07:08:21.000Z","updated":"2018-07-23T08:42:10.439Z","comments":true,"path":"note/213f2e85.html","link":"","permalink":"http://voidday.com/note/213f2e85.html","excerpt":"上周星期五的时候,完成了一次springcloud的小体验,现在把流程和想法记下来","text":"上周星期五的时候,完成了一次springcloud的小体验,现在把流程和想法记下来 前言 按照网上的教程来写的demo 首先需要一个服务端,还需要一个服务提供者,而且服务提供者需要把自己注册到服务端,另外还需要一个服务消费者,服务提供者也可以是服务消费者 熔断器Hystrix的话,就相当于短路机制.熔断器在什么情况先需要呢?我的理解是,比如在A调用B的服务表明上是直接调用的B,其实是A请求服务端,服务端在把B服务提供给A,如果发生A调用B,B在调用C,这个过程就是A请求服务端发送给了B,B在请求服务端,服务端在把C服务给B,B在给A;这种情况下如果C服务出现问题,或者延迟的话,B就会一直等待C的响应,然后A就会一直等待B的响应,要不到多久这种连锁反应就会让集群崩溃在这种情况下熔断器的作用就体现出来了熔断器会在,请求服务,服务出现多次错误或者延迟的情况下把出现错误或者延迟的服务关闭掉,让请求这个服务的其它程序回调(fallback),这样就不会出现集群的连锁反应 建立服务端 在最基本的springboot项目的pom.xml文件里面加入如下依赖: 12345678910111213141516&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 注意添加依赖的方式 修改配置文件 12345678910server: port: 1111eureka: client: # 这里把服务端注册自己到服务里改为false register-with-eureka: false fetch-registry: false serviceUrl: defaultZone: //localhost:$&#123;server.port&#125;/eureka/ 修改启动类 12345678@EnableEurekaServer@SpringBootApplicationpublic class SpringCloudDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudDemoApplication.class, args); &#125;&#125; 加入 @EnableEurekaServer 启动效果如下(我启动了两个服务提供方,设定了不同的端口,一个有say方法,一个没有): 创建服务提供者 在基本的springboot项目上添加依赖 123456789101112131415161718&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 修改配置 12345spring.application.name=compute-serviceserver.port=2222eureka.client.serviceUrl.defaultZone=http://localhost:1111/eureka/ 编写服务controller 123456789101112131415161718192021222324/** * 创建时间:2017/12/22 0022 * 创建人:lq */@RestControllerpublic class MyController &#123; private final Logger logger = Logger.getLogger(getClass()); @Autowired private DiscoveryClient client; @RequestMapping(value = \"/add\", method = RequestMethod.GET) public Integer add(@RequestParam Integer a, @RequestParam Integer b)&#123; ServiceInstance instance = client.getLocalServiceInstance(); Integer c = a + b; logger.info(\"/add, host:\" + instance.getHost() + \", service_id:\" + instance.getServiceId() + \", result:\" + c); return c; &#125;&#125; 在启动器上加入: @EnableDiscoveryClient注解,注册到服务中心 启动过后如图表明以及注册成功: 编写消费服务方 这里使用的 Feign 在最基本的springboot项目上添加依赖(注意添加依赖和上面的类型): 12345678910111213141516171819202122232425262728&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt;&lt;/dependency&gt; &lt;dependencyManagement&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;/dependencyManagement&gt; 修改配置 12345678910111213server: port: 3333spring: application: # 显示在服务中心的名字,以及调用时的名字? name: compute-serviceeureka: client: serviceUrl: #指定服务中心 defaultZone: http://localhost:1111/eureka/ 编写调用接口 1234567891011@FeignClient(\"compute-service\") // 指定调用的服务名public interface ComputeClient &#123; //这里访问的路径,请求方式,参数都必须和服务提供端的一样 @RequestMapping(value = \"/add\", method = RequestMethod.GET) Integer add(@RequestParam(value = \"a\") Integer a, @RequestParam(value = \"b\") Integer b); //测试方法 @RequestMapping(value = \"/say\", method = RequestMethod.GET) String say();&#125; 编写Controller进行测试 123456789101112131415161718@RestControllerpublic class My &#123; //注入接口 @Autowired ComputeClient computeClient; @RequestMapping(value = \"/add\", method = RequestMethod.GET) public Integer add() &#123; return computeClient.add(10, 20); &#125; @RequestMapping(value = \"/say\", method = RequestMethod.GET) public String say()&#123; return computeClient.say(); &#125;&#125; 修改启动类 1234567891011@SpringBootApplication@EnableDiscoveryClient@EnableFeignClientspublic class RibbonDemoApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(RibbonDemoApplication.class, args); &#125;&#125; 启动过后如图: 测试 这里我启动的两个服务提供方,端口指定不一样 访问服务消费者的add方法 第一次访问其中一个服务提供日志打印如下 再次访问add,另一个服务端打印结果 结论通过Feign以接口和注解配置的方式，轻松实现了对compute-service服务的绑定，这样我们就可以在本地应用中像本地服务一下的调用它，并且做到了客户端均衡负载。 但是如果访问3333的say方法,出现第一次访问如果是成功,第二次访问肯定404,这是因为启动了两个服务端,一个有say方法一个没有say方法,在Feign实现的客户端均衡负载的时候,是采用的遍历的方式应该,类似于上面的add方法,第一次访问第一个服务端,第二次访问第三个服务端.","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://voidday.com/categories/Spring-Cloud/"}],"tags":[{"name":"Spring,","slug":"Spring","permalink":"http://voidday.com/tags/Spring/"},{"name":"Cloud","slug":"Cloud","permalink":"http://voidday.com/tags/Cloud/"}]},{"title":"integer和integer比较是否相同用==的问题","slug":"今天遇到integer和integer比较是否相同的问题","date":"2017-12-25T06:06:56.000Z","updated":"2018-07-23T08:42:10.570Z","comments":true,"path":"note/79bb4db8.html","link":"","permalink":"http://voidday.com/note/79bb4db8.html","excerpt":"integer和integer比较是否相同的问题","text":"integer和integer比较是否相同的问题 今天在继续开发商城项目时,遇到一个问题,我根据地址取出用户ID(地址唯一),代码如下: 12345// 处理转账到自己的账户Integer userIdByAddress = getUserIdByAddress(address);if (userIdByAddress == Integer.valueOf(memberId)) &#123; return JsonResultUtil.getErrorJson(\"无法转账给自己\");&#125; 这里我测试的时候输入的自己的address也进入不了 在网上查了一下原因,大概是因为integer范围的问题 123456static final Integer cache[] = new Integer[-(-128) + 127 + 1]; static &#123; for(int i = 0; i &lt; cache.length; i++) cache[i] = new Integer(i - 128); &#125; 总结:这是源码中的，也就是说cache[]中已有-128到127，不在这范围的会新new ，这时可以理解比较是内存地址，也就是是不是同一对象.所以说当Integer的值不在-128到127的时候使用==方法判断是否相等就会出错，在这个范围之内的就会没有问题！以后最好用equals","categories":[{"name":"java开发遇到的问题","slug":"java开发遇到的问题","permalink":"http://voidday.com/categories/java开发遇到的问题/"}],"tags":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"http://voidday.com/tags/疑难杂症/"}]},{"title":"Spring Cloud自己学习的时候遇到的一些问题","slug":"Spring Cloud开发过程中遇到的一些问题","date":"2017-12-22T10:30:42.000Z","updated":"2018-07-23T08:42:10.431Z","comments":true,"path":"note/4551e774.html","link":"","permalink":"http://voidday.com/note/4551e774.html","excerpt":"Spring Cloud自己学习的时候遇到的一些问题","text":"Spring Cloud自己学习的时候遇到的一些问题 Feign pom.xml引起问题的配置部分如下: 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Brixton.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 报错内容 1Attribute 'value' in annotation [org.springframework.cloud.netflix.feign.FeignClient] must be declared as an @AliasFor [serviceId], not [name]. 解决方法 将Spring Cloud版本改为 Brixton.SR5 或 Camden.RELEASE ，即可解决此问题。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://voidday.com/categories/Spring-Cloud/"}],"tags":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"http://voidday.com/tags/疑难杂症/"}]},{"title":"IDEA新建项目时，没有Spring Initializr选项","slug":"IDEA新建项目时，没有Spring Initializr选项","date":"2017-12-22T08:17:16.000Z","updated":"2018-07-23T08:42:10.328Z","comments":true,"path":"note/6ed98f67.html","link":"","permalink":"http://voidday.com/note/6ed98f67.html","excerpt":"IDEA新建项目时，没有Spring Initializr选项","text":"IDEA新建项目时，没有Spring Initializr选项 最近开始使用IDEA作为开发工具，然后也是打算开始学习使用spring cloud。看着博客来进行操作上手spring cloud，很多都是说创建一个新项目(Create New Project) 选择 Spring Initializr。然而我发现我的IDEA上面没有Spring Initializr这个选项。解决办法如下： 在settings -&gt; Plugins 里面搜索spring boot，勾选上，然后再重启下idea，就可以了。如果Plugins里面没有spring boot的话，先安装下，再勾选","categories":[{"name":"IDEA","slug":"IDEA","permalink":"http://voidday.com/categories/IDEA/"}],"tags":[{"name":"疑难杂症","slug":"疑难杂症","permalink":"http://voidday.com/tags/疑难杂症/"}]},{"title":"Redis的更新策略(二)","slug":"Redis的更新策略(二)","date":"2017-12-22T06:02:06.000Z","updated":"2018-07-23T08:42:10.390Z","comments":true,"path":"note/746cbd91.html","link":"","permalink":"http://voidday.com/note/746cbd91.html","excerpt":"Spring Boot中的缓存支持（二）使用Redis做集中式缓存","text":"Spring Boot中的缓存支持（二）使用Redis做集中式缓存 前言 阅读了一些资料,发现了一个更好更便捷的处理Redis缓存的方法,所以本菜鸡写下来记录一下 这里主要是使用Cache注解,所以下面会介绍一些Cache注解的资料 Cache注解详解 @CacheConfig 用例: 1234567@CacheConfig(cacheNames = \"users\")public interface UserRepository extends JpaRepository&lt;User, Long&gt; &#123; @Cacheable User findByName(String name);&#125; @CacheConfig：主要用于配置该类中会用到的一些共用的缓存配置。在这里@CacheConfig(cacheNames = &quot;users&quot;)：配置了该数据访问对象中返回的内容将存储于名为users的缓存对象中，我们也可以不使用该注解，直接通过@Cacheable自己配置缓存集的名字来定义。 @Cacheable：配置了findByName函数的返回值将被加入缓存。同时在查询时，会先从缓存中获取，若不存在才再发起对数据库的访问。该注解主要有下面几个参数： value、cacheNames：两个等同的参数（cacheNames为Spring 4新增，作为value的别名），用于指定缓存存储的集合名。由于Spring 4中新增了@CacheConfig，因此在Spring 3中原本必须有的value属性，也成为非必需项了 key：缓存对象存储在Map集合中的key值，非必需，缺省按照函数的所有参数组合作为key值，若自己配置需使用SpEL表达式，比如：@Cacheable(key = &quot;#p0&quot;)：使用函数第一个参数作为缓存的key值 condition：缓存对象的条件，非必需，也需使用SpEL表达式，只有满足表达式条件的内容才会被缓存，比如：@Cacheable(key = &quot;#p0&quot;, condition = &quot;#p0.length() &lt; 3&quot;)，表示只有当第一个参数的长度小于3的时候才会被缓存 unless：另外一个缓存条件参数，非必需，需使用SpEL表达式。它不同于condition参数的地方在于它的判断时机，该条件是在函数被调用之后才做判断的，所以它可以通过对result进行判断 keyGenerator：用于指定key生成器，非必需。若需要指定一个自定义的key生成器，我们需要去实现org.springframework.cache.interceptor.KeyGenerator接口，并使用该参数来指定。需要注意的是：该参数与key是互斥的 cacheManager：用于指定使用哪个缓存管理器，非必需。只有当有多个时才需要使用 cacheResolver：用于指定使用那个缓存解析器，非必需。需通过org.springframework.cache.interceptor.CacheResolver接口来实现自己的缓存解析器，并用该参数指定。 几个核心注解: @CachePut：配置于函数上，能够根据参数定义条件来进行缓存，它与@Cacheable不同的是，它每次都会真是调用函数，所以主要用于数据新增和修改操作上。它的参数与@Cacheable类似，具体功能可参考上面对@Cacheable参数的解析 @CacheEvict：配置于函数上，通常用在删除方法上，用来从缓存中移除相应数据。除了同@Cacheable一样的参数之外，它还有下面两个参数： allEntries：非必需，默认为false。当为true时，会移除所有数据 beforeInvocation：非必需，默认为false，会在调用方法之后移除数据。当为true时，会在调用方法之前移除数据 更多详细用例参照","categories":[{"name":"Redis","slug":"Redis","permalink":"http://voidday.com/categories/Redis/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"http://voidday.com/tags/Redis/"}]},{"title":"SpringBoot整合mybatis","slug":"SpringBoot整合mybatis","date":"2017-12-22T03:42:54.000Z","updated":"2018-07-23T08:42:10.529Z","comments":true,"path":"note/d4e7c35f.html","link":"","permalink":"http://voidday.com/note/d4e7c35f.html","excerpt":"SpringBoot整合mybatis,测试简单的CURD","text":"SpringBoot整合mybatis,测试简单的CURD 前言 整合springboot和mybatis仅仅为了学习和简单的使用 导入依赖 在pom.xml中引入依赖,如下:123456&lt;!--引入mybatis,因为带有JDBC所以不需要引入JDBC了--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt; 实体类 这里实体类,我是用的测试JPA时的实体类,也可以按照平常的写法,先private字段,在get,set也可以1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768package com.example.demo.model;import javax.persistence.*;import java.io.Serializable;@Entity@Table(name=\"user\")public class SystemUser implements Serializable&#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) //id自增 @Column(name = \"id\") private Integer id; @Column(name=\"user_name\") private String name; @Column(name=\"user_password\") private String password; public SystemUser(String name, String password, Integer id) &#123; this.name = name; this.password = password; this.id = id; &#125; public SystemUser(String name, String password) &#123; this.name = name; this.password = password; &#125; @Override public String toString() &#123; return \"SystemUser&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", password='\" + password + '\\'' + '&#125;'; &#125; public SystemUser() &#123; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; &#125; 编写Dao层1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.example.mybatisDeno.mapper;import com.example.demo.model.SystemUser;import org.apache.ibatis.annotations.*;import java.util.List;/** * 创建时间:2017/12/22 0022 * 创建人:lq * 使用注解进行简单的增删改查 */@Mapper //@Mapper将UserDao声明为一个Mapper接口public interface UserDao &#123; @Results(&#123; @Result(property = \"id\", column = \"id\"), @Result(property = \"name\", column = \"user_name\"), @Result(property = \"password\", column = \"user_password\") &#125;) /** * 查询 */ @Select(\"SELECT * FROM user WHERE user_name = #&#123;name&#125;\") //3 List&lt;SystemUser&gt; get(String name); /** * 增加,返回增加元素的ID * @param user SystemUser实体 * @return 返回增加元素ID */ @Insert(\"INSERT INTO `user`(user_name,user_password) VALUES(#&#123;name&#125;,#&#123;password&#125;)\") @Options(useGeneratedKeys = true, keyColumn = \"id\", keyProperty = \"id\") Integer add(SystemUser user); /** * 删除 * @param id * @return 返回影响的行数 */ @Delete(\"Delete from user where id = #&#123;id&#125;\") Long delete(Integer id); /** * 修改 * @param user SystemUser实体 * @return 返回影响的行数 */ @Update(\"update user set user_name = #&#123;name&#125;, user_password = #&#123;password&#125; where id = #&#123;id&#125;\") Long update(SystemUser user);&#125; @Mapper 将UserDao声明为一个Mapper接口 @Results 字段与数据库的映射列表 @Result 进行详细的映射,其中property是User类的属性名，colomn是数据库表的字段名 @Select 写入查询 @Update 写入更新语句 @Delete 写入删除语句 @Insert 写入插入语句 @Options 设置主键,其中useGeneratedKeys是使用主键,keyProperty实体类中主键的名字,keyColumn数据库中主键的名字 编写service层 如下;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.example.mybatisDeno.service;import com.example.demo.model.SystemUser;import com.example.mybatisDeno.mapper.UserDao;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;/** * 创建时间:2017/12/22 0022 * 创建人:lq */@Servicepublic class UserService &#123; @Autowired private UserDao userDao; /** * 根据name查询 * @param name * @return */ public List&lt;SystemUser&gt; get(String name)&#123; return userDao.get(name); &#125; /** * 增加 * @param name,password * @return */ public Integer add(String name, String password)&#123; SystemUser user = new SystemUser(name,password); return userDao.add(user); &#125; /** * 删除 * @param id * @return */ public Long delete(Integer id)&#123; return userDao.delete(id); &#125; /** * 修改 * @param name,password * @return */ public Long update(String name, String password, Integer id)&#123; SystemUser user = new SystemUser(name, password, id); return userDao.update(user); &#125;&#125; 编写controller层12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.example.mybatisDeno.controller;import com.example.demo.model.SystemUser;import com.example.mybatisDeno.service.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import java.util.List;/** * 创建时间:2017/12/22 0022 * 创建人:lq */@RestController@RequestMapping(value = \"/mb\")public class UserController &#123; @Autowired private UserService userService; @RequestMapping(value = \"/\") public String hello()&#123; return \"mybatis\"; &#125; @RequestMapping(value = \"/get\") public List&lt;SystemUser&gt; get(@RequestParam String name)&#123; return userService.get(name); &#125; @RequestMapping(value = \"/add\") public Integer add(@RequestParam String name, @RequestParam String password)&#123; return userService.add(name, password); &#125; @RequestMapping(value = \"/delete\") public Long delete(@RequestParam Integer id)&#123; return userService.delete(id); &#125; @RequestMapping(value = \"/update\") public Long update(@RequestParam String name, @RequestParam String password, @RequestParam Integer id)&#123; return userService.update(name, password ,id); &#125;&#125; 总结 这里详细说明一下MyBatis注解 使用@Param如下代码: 12@Insert(\"INSERT INTO USER(NAME, AGE) VALUES(#&#123;name&#125;, #&#123;age&#125;)\")int insert(@Param(\"name\") String name, @Param(\"age\") Integer age); 这种方式很好理解，@Param中定义的name对应了SQL中的#{name}，age对应了SQL中的#{age} 使用Map如下代码: 12@Insert(\"INSERT INTO USER(NAME, AGE) VALUES(#&#123;name,jdbcType=VARCHAR&#125;, #&#123;age,jdbcType=INTEGER&#125;)\")int insertByMap(Map&lt;String, Object&gt; map); 对于Insert语句中需要的参数，我们只需要在map中填入同名的内容即可，具体如下面代码所示： 1234Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();map.put(\"name\", \"CCC\");map.put(\"age\", 40);userMapper.insertByMap(map); 使用对象 可直接使用普通的Java对象来作为查询条件的传参，比如我们可以直接使用User对象: 12@Insert(\"INSERT INTO USER(NAME, AGE) VALUES(#&#123;name&#125;, #&#123;age&#125;)\")int insertByUser(User user);","categories":[{"name":"SoringBoot","slug":"SoringBoot","permalink":"http://voidday.com/categories/SoringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"mybatis","slug":"mybatis","permalink":"http://voidday.com/tags/mybatis/"}]},{"title":"SoringBoot正常启动,但是页面Whitelabel Error Page","slug":"SpringBoot正常启动,但是页面Whitelabel Error Page","date":"2017-12-22T03:13:12.000Z","updated":"2018-07-23T08:42:10.534Z","comments":true,"path":"note/cd2213ac.html","link":"","permalink":"http://voidday.com/note/cd2213ac.html","excerpt":"SoringBoot正常启动,但是页面Whitelabel Error Page","text":"SoringBoot正常启动,但是页面Whitelabel Error Page 环境: idea + springboot 项目结构如下: 情况描述:启动DemoApplication正常启动没报任何错误,访问mybatisDemo下的controller无法访问,但是访问demo下的controller可以访问. 问题原因:我觉得spring boot只会扫描启动类当前包和以下的包,如果将启动类放到demo下,就只会扫描demo下的 解决方法:将启动类放到mybatisDemo下","categories":[{"name":"SoringBoot","slug":"SoringBoot","permalink":"http://voidday.com/categories/SoringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"启动报错","slug":"启动报错","permalink":"http://voidday.com/tags/启动报错/"}]},{"title":"Redis的更新策略","slug":"Redis的更新策略","date":"2017-12-20T02:23:12.000Z","updated":"2018-07-23T08:42:10.395Z","comments":true,"path":"note/caef1698.html","link":"","permalink":"http://voidday.com/note/caef1698.html","excerpt":"SpringBoot + Redis的缓存更新策略","text":"SpringBoot + Redis的缓存更新策略 前言 这里才用的模式为Cache Aside,这是标准的design pattern.它的具体逻辑如下: 失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。 命中：应用程序从cache中取数据，取到后返回。 更新：先把数据存到数据库中，成功后，再让缓存失效。 详细资料:缓存更新的套路 项目具体配置 pom.xml依赖配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.9.RELEASE&lt;/version&gt; &lt;relativePath /&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 核心模块，包括自动配置支持、日志和YAML --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 测试模块，包括JUnit、Hamcrest、Mockito --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- 引入web依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入JDBC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 引入MYSQL驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- JPA --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--redis配置依赖关系--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 配置数据源1234567#mysqlspring: datasource: url: jdbc:mysql://localhost:3306/test driver-class-name: com.mysql.jdbc.Driver username: root password: root 配置JPA1234567891011121314151617181920212223#jpa jpa: #指定JPA数据库 database: mysql #showSql show-sql: true #hibernate.hbm2ddl.auto节点的值有几个create、create-drop、update、validate、none #create：每次加载hibernate会自动创建表，以后启动会覆盖之前的表，所以这个值基本不用，严重会导致的数据的丢失。 #create-drop ： 每次加载hibernate时根据model类生成表，但是sessionFactory一关闭，表就自动删除，下一次启动会重新创建。 #update：加载hibernate时根据实体类model创建数据库表，这是表名的依据是@Entity注解的值或者@Table注解的值，sessionFactory关闭表不会删除，且下一次启动会根据实体model更新结构或者有新的实体类会创建新的表。 #validate：启动时验证表的结构，不会创建表 #none：启动时不做任何操作 hibernate: ddl-auto: none #命名策略 naming: strategy: org.hibernate.cfg.ImprovedNamingStrategy 配置Redis123456789101112131415161718192021#redis redis: #Redis数据库索引（默认为0） database: 0 # Redis服务器地址 host: 192.168.3.58 # Redis服务器连接端口 port: 6379 # Redis服务器连接密码(默认为空) password: pool: # 连接池最大连接数（使用负值表示没有限制） maxActice: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） maxWait: -1 # 连接池中的最大空闲连接 maxIdle: 8 # 连接池中的最小空闲连接 minIdle: 0 # 连接超时时间（毫秒） timeout: 0 建立实体类 下面的开发全部基于SpringBoot + JPA + Redis 实体类如下(必须实现序列化):1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.example.demo.model;import javax.persistence.*;import java.io.Serializable;@Entity@Table(name=\"user\")public class SystemUser implements Serializable&#123; @Id @GeneratedValue(strategy = GenerationType.IDENTITY) //id自增 @Column(name = \"id\") private Integer id; @Column(name=\"user_name\") private String name; @Column(name=\"user_password\") private String password; public SystemUser(String name, String password) &#123; this.name = name; this.password = password; &#125; @Override public String toString() &#123; return \"SystemUser&#123;\" + \"id=\" + id + \", name='\" + name + '\\'' + \", password='\" + password + '\\'' + '&#125;'; &#125; public SystemUser() &#123; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getPassword() &#123; return password; &#125; public void setPassword(String password) &#123; this.password = password; &#125; &#125; 缓存更新策略的具体实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package com.example.demo.controller;import com.example.demo.model.SystemUser;import com.example.demo.service.IUserService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.ValueOperations;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.concurrent.TimeUnit;/** * 创建时间:2017/12/20 0020 * 创建人:lq */@RestController@RequestMapping(value = \"redis\")public class RedisController &#123; private Logger log = LoggerFactory.getLogger(\"RedisDemo\"); @Autowired private IUserService userService; @Autowired private RedisTemplate redisTemplate; /** * 获取User逻辑 * 如果缓存中存在就从缓存区取出 * 不存在就从DB中取出,然后插入缓存 * @param id * @return */ @RequestMapping(value = \"find\") public SystemUser findOne(Integer id)&#123; String key = \"User_id\" + id; //如果缓存中存在就取出 if (redisTemplate.hasKey(key))&#123; SystemUser user = (SystemUser) redisTemplate.opsForValue().get(key); log.info(\"RedisController.findOne():从缓存中取出SystemUser &gt;&gt;&gt;\" + user.toString()); return user; &#125; //不存在就在DB中取出 SystemUser user = userService.findOne(id); //插入缓存 redisTemplate.opsForValue().set(key, user, 60, TimeUnit.SECONDS); log.info(\"RedisController.findOne():插入User缓存 &gt;&gt;&gt;\" + user.toString()); return user; &#125; /** * 更新User逻辑 * 先更新 * 如果缓存存在删除,不存在不操作 */ @RequestMapping(value = \"up\") public SystemUser update()&#123; SystemUser user = new SystemUser(); user.setId(2); user.setPassword(\"123\"); user.setName(\"p\"); userService.save(user); String key = \"User_id\" + user.getId(); if (redisTemplate.hasKey(key))&#123; log.info(\"RedisController.update():从缓存中移除SystemUser &gt;&gt;&gt;\" + user.toString()); redisTemplate.delete(key); &#125; return user; &#125;&#125; 第一次访问findOne(): 访问修改方法update(): 再次访问查找findOne(): 总结 采用Cache Aside的话,并发操作的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。","categories":[{"name":"Redis","slug":"Redis","permalink":"http://voidday.com/categories/Redis/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"http://voidday.com/tags/Redis/"}]},{"title":"SpringBoot整合Redis","slug":"SpringBoot 整合Redis","date":"2017-12-19T09:48:12.000Z","updated":"2018-07-23T08:42:10.452Z","comments":true,"path":"note/4ebad2d4.html","link":"","permalink":"http://voidday.com/note/4ebad2d4.html","excerpt":"记录下第一整合过程","text":"记录下第一整合过程 [TOC] 1前言 Redis服务器在虚拟机中搭建,系统为Ubuntu,Redis版本为4.0.6;文件配置均在application.yml中完成 2.springBoot添加Redis依赖 在pom.xml添加依赖:12345&lt;!--redis配置依赖关系--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 3.Redis单机配置123456789101112131415161718192021#redis redis: #Redis数据库索引（默认为0） database: 0 # Redis服务器地址 host: 192.168.3.58 # Redis服务器连接端口 port: 6379 # Redis服务器连接密码(默认为空) password: pool: # 连接池最大连接数（使用负值表示没有限制） maxActice: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） maxWait: -1 # 连接池中的最大空闲连接 maxIdle: 8 # 连接池中的最小空闲连接 minIdle: 0 # 连接超时时间（毫秒） timeout: 0 4.编写Redis测试用例这个用例中完成了Redis对字符的存储,和对对象的存储注意: SystemUser这个对象必须实现Serializable接口,否则会报错 RedisDemo.java 12345678910111213141516171819202122232425262728293031/** * 创建时间:2017/12/19 0019 * 创建人:lq * Redis简单存取操作 */@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = DemoApplication.class)public class RedisDemo &#123; @Autowired private RedisTemplate redisTemplate; @Autowired private StringRedisTemplate stringRedisTemplate; private Logger log = LoggerFactory.getLogger(\"RedisDemo\"); @Test public void test()&#123; stringRedisTemplate.opsForValue().set(\"name\",\"pock\"); SystemUser user = new SystemUser(\"admin\",\"123\"); redisTemplate.opsForValue().set(\"user\",user); log.info(\"success\"); &#125; @After public void testGet()&#123; SystemUser user = (SystemUser) redisTemplate.opsForValue().get(\"user\"); log.info(user.getName()); &#125;&#125; RedisTemplate:会使用JdkSerializationRedisSerializer，这意味着key和value都会通过Java进行序列化。 StringRedisTemplate默认会使用StringRedisSerializer 结束到这里就实现了一个最简单的springboot整合Redis的demo","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"Redis","slug":"Redis","permalink":"http://voidday.com/tags/Redis/"}]},{"title":"SpringBoot依赖整理","slug":"SpringBoot依赖整理","date":"2017-12-19T06:09:00.000Z","updated":"2018-07-23T08:42:10.471Z","comments":true,"path":"note/ab1c9965.html","link":"","permalink":"http://voidday.com/note/ab1c9965.html","excerpt":"整理下吧","text":"整理下吧 前言 以下的配置全部在application.yml文件中配置 均为在学习过程中的总结1.核心模块 核心模块，包括自动配置支持、日志和YAML12345&lt;!-- 核心模块，包括自动配置支持、日志和YAML --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt; 2.测试模块 测试模块，包括JUnit、Hamcrest、Mockito123456&lt;!-- 测试模块，包括JUnit、Hamcrest、Mockito --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 3.web依赖 web依赖12345&lt;!-- 引入web依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 4.JDBC依赖 JDBC依赖 12345&lt;!-- 引入JDBC --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt; 参数配置 1234567#mysqlspring: datasource: url: jdbc:mysql://localhost:3306/test driver-class-name: com.mysql.jdbc.Driver username: root password: root 5.MYSQL驱动 MYSQL驱动12345&lt;!-- 引入MYSQL驱动 --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 6.引入JPA 引入JPA 12345&lt;!-- JPA --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt; 参数配置 1234567891011121314151617181920212223#jpa jpa: #指定JPA数据库 database: mysql #showSql show-sql: true #hibernate.hbm2ddl.auto节点的值有几个create、create-drop、update、validate、none #create：每次加载hibernate会自动创建表，以后启动会覆盖之前的表，所以这个值基本不用，严重会导致的数据的丢失。 #create-drop ： 每次加载hibernate时根据model类生成表，但是sessionFactory一关闭，表就自动删除，下一次启动会重新创建。 #update：加载hibernate时根据实体类model创建数据库表，这是表名的依据是@Entity注解的值或者@Table注解的值，sessionFactory关闭表不会删除，且下一次启动会根据实体model更新结构或者有新的实体类会创建新的表。 #validate：启动时验证表的结构，不会创建表 #none：启动时不做任何操作 hibernate: ddl-auto: none #命名策略 naming: strategy: org.hibernate.cfg.ImprovedNamingStrategy 7.引入Redis12345&lt;!--redis配置依赖关系--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; Redis单机参数配置123456789101112131415161718192021#redis redis: #Redis数据库索引（默认为0） database: 0 # Redis服务器地址 host: 192.168.3.58 # Redis服务器连接端口 port: 6379 # Redis服务器连接密码(默认为空) password: pool: # 连接池最大连接数（使用负值表示没有限制） maxActice: 8 # 连接池最大阻塞等待时间（使用负值表示没有限制） maxWait: -1 # 连接池中的最大空闲连接 maxIdle: 8 # 连接池中的最小空闲连接 minIdle: 0 # 连接超时时间（毫秒） timeout: 0 引入mybatis12345&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt; 引入cassandra数据库?12345&lt;!--引入cassandra数据库?--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-cassandra&lt;/artifactId&gt;&lt;/dependency&gt; springboot热部署1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;&lt;/dependency&gt;","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"依赖","slug":"依赖","permalink":"http://voidday.com/tags/依赖/"}]},{"title":"SpringBoot启动报错The import org.springframework.data.repository.query.Param cannot be resolved","slug":"SpringBoot启动报错 The import org.springframework.data.repository.query.Param cannot be resolved","date":"2017-12-19T02:31:31.000Z","updated":"2018-07-23T08:42:10.519Z","comments":true,"path":"note/de8bd00d.html","link":"","permalink":"http://voidday.com/note/de8bd00d.html","excerpt":"SpringBoot启动报错The import org.springframework.data.repository.query.Param cannot be resolved","text":"SpringBoot启动报错The import org.springframework.data.repository.query.Param cannot be resolved 描述:在sprigBoot启动时遇到:The import org.springframework.data.repository.query.Param cannot be resolved 解决方式mvn clean dependency:tree 命令看看依赖是否有问题在运行mvn clean compile看是否失败,成功就没啥问题了 到这里重新启动就解决了问题","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"报错","slug":"报错","permalink":"http://voidday.com/tags/报错/"}]},{"title":"SpringBoot异常统一处理","slug":"SpringBoot异常统一处理","date":"2017-12-18T03:40:00.000Z","updated":"2018-07-23T08:42:10.525Z","comments":true,"path":"note/5bde82b9.html","link":"","permalink":"http://voidday.com/note/5bde82b9.html","excerpt":"SpringBoot异常统一处理(初学记录下)","text":"SpringBoot异常统一处理(初学记录下) 1.建立测试异常123456789@RestController@RequestMapping(value = \"/ecpc\")public class ExceptionController &#123; @RequestMapping(value = \"/ecpc1\") public String ecpcTest() throws Exception &#123; throw new Exception(\"发生错误\"); &#125;&#125; 不进行处理的话访问 http://localhost:8080/ecpc/ecpc1,会出下面的界面 2.统一异常处理类123456789101112@RestControllerAdvice //定义统一的异常处理类public class GlobalExceptionHandler &#123; private Logger log = LoggerFactory.getLogger(\"GlobalExceptionHandler\"); @ResponseBody @ExceptionHandler(value = Exception.class ) //定义针对的异常类型,这里捕获Exception类型和其所用子异常 public Object errorHandler(HttpServletRequest req, Exception e) throws Exception &#123; log.error(\"---DefaultException Handler---Host &#123;&#125; invokes url &#123;&#125; ERROR: &#123;&#125;\",req.getRemoteHost(),req.getRequestURL(),e.getMessage()); return e.getMessage(); &#125;&#125; @RestControllerAdvice 表明GlobalExceptionHandler 是一个全局的异常处理器,也是是一个 RESTful Controller, 即它会以 RESTful 的形式返回回复.(类注解, 作用于 整个 Spring 工程. ControllerAdvice 注解定义了一个全局的异常处理器,如果你们的异常需要返回页面啊之类的，你可以使用@ControllerAdvice分别定制。) ExceptionHandler(value = Exception.class ) 表示 defaultErrorHandler 会处理 Exception 异常和其所用子异常(作用于 Controller 级别. ExceptionHandler 注解为一个 Controler 定义一个异常处理器) 捕获效果如图: 控制台打印效果如图:","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"异常处理","slug":"异常处理","permalink":"http://voidday.com/tags/异常处理/"}]},{"title":"SpringBoot注解随记","slug":"SpringBoot注解随记","date":"2017-12-15T12:14:52.000Z","updated":"2018-07-23T08:42:10.548Z","comments":true,"path":"note/17a32c5f.html","link":"","permalink":"http://voidday.com/note/17a32c5f.html","excerpt":"记录一些工作中遇到的注解方便以后查找,2017年12月19日","text":"记录一些工作中遇到的注解方便以后查找,2017年12月19日 前言记录一些工作中遇到的注解方便以后查找,2017年12月19日 @RestController @RestController4.0之前的版本，SpringMVC的组件都使用@Controller来标识当前类是一个控制器servlet,现在@RestController 就相当于标识当前类为Controller,支持返回xml和json @RequestMapping @RequestMapping(value=&quot;/users&quot;)在Controller层上配置 1234@RestController@RequestMapping(value = \"/user\") // 通过这里配置使下面的映射都在/user下public class UserController &#123;&#125; @RequestMapping(value=”/“, method=RequestMethod.GET)这里指定了访问的类型GET,相似的还有 Method 请求类型 method=RequestMethod.GET GET请求 method=RequestMethod.POST POST请求 method=RequestMethod.PUT PUT请求 method=RequestMethod.DELETE DELETE请求 可以用这个方式实现RESTful API RESTful API设计思想大概: 请求类型 URL 功能说明 GET /users 查询用户列表 POST /users 创建一个用户 GET /users?id= 根据ID查询一个用户 PUT /users?id= 根据ID更新一个用户 DELETE /users?id= 根据ID删除一个用户 示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647 @RestController @RequestMapping(value=\"/users\") // 通过这里配置使下面的映射都在/users下 public class UserController &#123; @RequestMapping(value=\"/\", method=RequestMethod.GET) public List&lt;User&gt; getUserList() &#123; // 处理\"/users/\"的GET请求，用来获取用户列表 // 还可以通过@RequestParam从页面中传递参数来进行查询条件或者翻页信息的传递 List&lt;User&gt; r = new ArrayList&lt;User&gt;(users.values()); return r; &#125; @RequestMapping(value=\"/\", method=RequestMethod.POST) public String postUser(@ModelAttribute User user) &#123; // 处理\"/users/\"的POST请求，用来创建User // 除了@ModelAttribute绑定参数之外，还可以通过@RequestParam从页面中传递参数 users.put(user.getId(), user); return \"success\"; &#125; @RequestMapping(value=\"/&#123;id&#125;\", method=RequestMethod.GET) public User getUser(@PathVariable Long id) &#123; // 处理\"/users/&#123;id&#125;\"的GET请求，用来获取url中id值的User信息 // url中的id可通过@PathVariable绑定到函数的参数中 return users.get(id); &#125; @RequestMapping(value=\"/&#123;id&#125;\", method=RequestMethod.PUT) public String putUser(@PathVariable Long id, @ModelAttribute User user) &#123; // 处理\"/users/&#123;id&#125;\"的PUT请求，用来更新User信息 User u = users.get(id); u.setName(user.getName()); u.setAge(user.getAge()); users.put(id, u); return \"success\"; &#125; @RequestMapping(value=\"/&#123;id&#125;\", method=RequestMethod.DELETE) public String deleteUser(@PathVariable Long id) &#123; // 处理\"/users/&#123;id&#125;\"的DELETE请求，用来删除User users.remove(id); return \"success\"; &#125; &#125; @PathVariable @PathVariable作用:映射 URL 绑定的占位符示例:1234567//@PathVariable可以用来映射URL中的占位符到目标方法的参数中@RequestMapping(\"/testPathVariable/&#123;id&#125;\") public String testPathVariable(@PathVariable(\"id\") Integer id) &#123; System.out.println(\"testPathVariable:\"+id); return SUCCESS; &#125; @ModelAttribute @ModelAttribute1234@RequestMapping(value=\"/\", method=RequestMethod.POST) public String postUser(@ModelAttribute User user) &#123; // 处理POST请求，用来创建User &#125; @RequestParam @RequestParam一种是request.getParameter(&quot;name&quot;)，另外一种是用注解@RequestParam直接获取示例12345678910@RequestMapping(\"testRequestParam\") public String filesUpload(@RequestParam String inputStr, HttpServletRequest request) &#123; System.out.println(inputStr); int inputInt = Integer.valueOf(request.getParameter(\"inputInt\")); System.out.println(inputInt); // ......省略 return \"index\"; &#125; @ControllerAdvice @ControllerAdvice作用于 整个 Spring 工程. ControllerAdvice 注解定义了一个全局的异常处理器,详情在异常处理的那一篇博客里面@ControllerAdvice呢也有个相似的@RestControllerAdvice @ExceptionHandler捕获异常,以及异常的子类,详细用法在在异常处理的那一篇博客里面 @RunWith @RunWith使用RunWith注解改变JUnit的默认执行类，并实现自已的Listener在平时的单元测试，如果不使用RunWith注解，那么JUnit将会采用默认的执行类Suite执行，如下类： 12345678public class SimpleJunitTest &#123; @Test public void testSayHi() &#123; System.out.println(\"Hi Junit.\"); &#125; &#125; @RunWith(SpringJUnit4ClassRunner.class)，这里就指定的是SpringJUnit4ClassRunner.class,如下类: 1234567891011121314151617181920@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = MockServletContext.class)public class HttpTest &#123; private MockMvc mvc; @Before public void setUp() throws Exception &#123; //绑定需要测试的Controller到MockMvc上 mvc = MockMvcBuilders.standaloneSetup(new HelloWordTest()).build(); &#125; @Test public void getHello() throws Exception &#123; //发出请求，在请求中可以设置一个http request可设置的所有参数 mvc.perform(MockMvcRequestBuilders.get(\"/basic/hello\").accept(MediaType.APPLICATION_JSON)) .andExpect(status().isOk()) .andExpect(content().string(equalTo(\"hello\"))); &#125;&#125; @SpringApplicationConfiguration @SpringApplicationConfiguration废弃 @SpringBootTest @SpringBootTest@SpringBootTest替代了@SpringApplicationConfiguration具体用法规定启动容器?如下类:1234567891011121314@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTest(classes = DemoApplication.class)public class RedisDemo &#123; @Test public void test()&#123; //测试方法 &#125; @After public void testGet()&#123; //测试方法 &#125;&#125; @DataJpaTest @DataJpaTest目前我已知的可用在测试JPA中(毕竟我还是个菜鸟)@DataJpaTest注解它只扫描@Entity 和装配 Spring Data JPA 存储库，其他常规的@Component（包括@Service、@Repository等）Bean 则不会被加载到 Spring 测试环境上下文。如下类:123456789101112131415161718@RunWith(SpringRunner.class)@DataJpaTestpublic class UserRepositoryInMemoryTest &#123; @Autowired private UserRepository userRepository; @Test public void testSave() &#123; User user = new User(); user.setName(\"fanlychie\"); userRepository.save(user); System.out.println(\"====================================\"); System.out.println(userRepository.findAll()); System.out.println(\"====================================\"); &#125; &#125; @Entity,@Table,@Id,@GeneratedValue,@Column @Entity,@Entity,@Table,@Id,@GeneratedValue,@Column 这里把这几个注解一起记录,因为一般都是在一起用的具体使用的方法如下类(结合JPA使用):12345678910111213141516@Entity //表明为实体类@Table(name=\"user\") //指定对应的表public class SystemUser implements Serializable&#123; @Id //表明主键 @GeneratedValue(strategy = GenerationType.IDENTITY) //表明id为自增 @Column(name = \"id\") //在表中对应的字段 private Integer id; @Column(name=\"user_name\") private String name; @Column(name=\"user_password\") private String password; //....省略Geter,Seter&#125; @Mapper,@Results,@Result,@Select,@Update,@Delete,@Insert,@Options @Mapper将UserDao声明为一个Mapper接口 @Results 字段与数据库的映射列表 @Result 进行详细的映射,其中property是User类的属性名，colomn是数据库表的字段名 @Select 写入查询 @Update 写入更新语句 @Delete 写入删除语句 @Insert 写入插入语句 @Options 设置主键,其中useGeneratedKeys是使用主键,keyProperty实体类中主键的名字,keyColumn数据 详细的用法可以参照…. @GetMapping,@PostMapping,@PutMapping,@DeleteMapping,@PatchMapping 这些注解是spring4.3引进的,自己感觉更便于开发RESTful风格的接口 拿 以@GetMapping为例，Spring官方文档说：@GetMapping是一个组合注解，是@RequestMapping(method = RequestMethod.GET)的缩写。该注解将HTTP Get 映射到 特定的处理方法上。 其它的同理 @SpringBootApplication @SpringBootApplication 在springboot的启动类上,具体如下: 12345678import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication //开启组件扫描和自动配置public class ReadingListApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ReadingListApplication.class, args); //负责启动引导应用程序 &#125;&#125; @SpringBootApplication 开启了Spring的组件扫描和Spring Boot的自动配置功能。实际上， @SpringBootApplication 将三个有用的注解组合在了一起 Spring的 @Configuration ：标明该类使用Spring基于Java的配置。 Spring的 @ComponentScan ：启用组件扫描，这样你写的Web控制器类和其他组件才能被自动发现并注册为Spring应用程序上下文里的Bean Spring Boot 的 @EnableAutoConfiguration ： 这 个 不 起 眼 的 小 注 解 也 可 以 称 为@Abracadabra @SpringApplicationConfiguration @SpringApplicationConfiguration 1@SpringApplicationConfiguration(classes = ReadingListApplication.class) 通过 Spring Boot加载上下文","categories":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://voidday.com/categories/SpringBoot/"}],"tags":[{"name":"SpringBoot,","slug":"SpringBoot","permalink":"http://voidday.com/tags/SpringBoot/"},{"name":"注解","slug":"注解","permalink":"http://voidday.com/tags/注解/"}]}]}